{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88f76647",
   "metadata": {},
   "source": [
    "https://archive.ics.uci.edu/dataset/462/drug+review+dataset+drugs+com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e684ae8b",
   "metadata": {},
   "source": [
    "# Flatiron Phase 5 Project\n",
    "\n",
    "## Aaron Galbraith\n",
    "\n",
    "https://www.linkedin.com/in/aarongalbraith \\\n",
    "https://github.com/aarongalbraith\n",
    "\n",
    "### Submitted: November 21, 2023\n",
    "\n",
    "## working contents\n",
    "\n",
    "- **[functions](#functions)<br>**\n",
    "- **[rough overview](#rough-overview)<br>**\n",
    "- **[missing values](#missing-values)<br>**\n",
    "- **[duplicates](#duplicates)<br>**\n",
    "- **[brand / generic pairs](#brand-/-generic-pairs)<br>**\n",
    "- **[further exploration of duplicates (skip for now)](#further-exploration-of-duplicates-(skip-for-now))<br>**\n",
    "- **[contractions](#contractions)<br>**\n",
    "- **[dates](#dates)<br>**\n",
    "- **[ratings](#ratings)<br>**\n",
    "- **[focusing on birth control](#focusing-on-birth-control)<br>**\n",
    "- **[save and reload preprocessed set](#save-and-reload-preprocessed-set)<br>**\n",
    "- **[feature engineering ideas](#feature-engineering-ideas)<br>**\n",
    "- **[rudimentary word cloud maker](#rudimentary-word-cloud-maker)<br>**\n",
    "- **[end](#end)<br>**\n",
    "\n",
    "\n",
    "## Contents\n",
    "\n",
    "- **[Business Understanding](#Business-Understanding)<br>**\n",
    "- **[Data Understanding](#Data-Understanding)**<br>\n",
    "- **[Data Preparation](#Data-Preparation)**<br>\n",
    "- **[Exploration](#Exploration)**<br>\n",
    "- **[Modeling](#Modeling)**<br>\n",
    "- **[Evaluation](#Evaluation)**<br>\n",
    "- **[Recommendations](#Recommendations)<br>**\n",
    "- **[Further Inquiry](#Further-Inquiry)**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd79a1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import html\n",
    "import contractions\n",
    "\n",
    "import re\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, accuracy_score, precision_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "SEED = 1979\n",
    "\n",
    "do_grids = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57df0016",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.read_csv('../data/drugsComTrain_raw.tsv', delimiter='\\t', encoding='latin-1')\n",
    "d2 = pd.read_csv('../data/drugsComTest_raw.tsv', delimiter='\\t', encoding='latin-1')\n",
    "df = pd.concat([d1,d2]).reset_index().drop(columns=['Unnamed: 0', 'index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe147e8",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75194ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_review(index):\n",
    "    print(df.review.loc[index])\n",
    "    display(df[df.review == df.loc[index].review][['drugName', 'condition', 'rating', 'date', 'usefulCount']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c6639c",
   "metadata": {},
   "source": [
    "# rough overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35353f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd0c05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d017402",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7121bb41",
   "metadata": {},
   "source": [
    "There are some missing condition labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b38533",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drugName.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e021dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drugName.value_counts().quantile(.90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921af3db",
   "metadata": {},
   "source": [
    "There are 3,671 unique drug names, and 10% of the drug names have more than 120 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e79f682",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcafdf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition.value_counts().quantile(.90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49a7d76",
   "metadata": {},
   "source": [
    "There are 916 unique conditionis, and 10% of the conditions have more than 332 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8b4a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rating.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc4973c",
   "metadata": {},
   "source": [
    "Most of the conditions lie at the extremes, and more of them appear to be at the positive extreme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04b8180",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('drugName').condition.nunique().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344e2d54",
   "metadata": {},
   "source": [
    "This means that, for example, 1869 drugs treat 1 condition only, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4e9c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('condition').drugName.nunique().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17380ea1",
   "metadata": {},
   "source": [
    "This means that 188 conditions are treatable by two drugs, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc9f216",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "print(df.drugName.value_counts())\n",
    "pd.set_option(\"display.max_rows\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745ce191",
   "metadata": {},
   "source": [
    "A casual overview of the drug names indicates that they all seem valid. Some seem to specify drug combinations and/or dosage amounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e70e86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "print(df.condition.value_counts())\n",
    "pd.set_option(\"display.max_rows\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fb070b",
   "metadata": {},
   "source": [
    "Oddly, the condition labels often (always?) omit initial 'F' and terminal 'r'. We can isolate instances of the former by searching for conditions that start with a lower case letter.\n",
    "\n",
    "We will eventually trim our records to a number of conditions that Planned Parenthood specializes in treating, but we will need all the records to help us determine missing condition labels. After we have restored (or discarded) all missing condition labels, we can drop the conditions outside the scope of this review."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20389159",
   "metadata": {},
   "source": [
    "## dates\n",
    "\n",
    "(Do this date analysis *after* we have trimmed to just the records we'll use?)\n",
    "\n",
    "There's probably a datetime method for this, but the following will produce month // day // year, and then we can figure out the earliest and latest dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22707cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = df.date.apply(lambda x: re.split(r'\\W+', x)[0])\n",
    "df['day'] = df.date.apply(lambda x: int(re.split(r'\\W+', x)[1]))\n",
    "df['year'] = df.date.apply(lambda x: int(re.split(r'\\W+', x)[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6ec208",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.year.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c824511",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.year == 2008].month.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e59fd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.year == 2008) &\n",
    "   (df.month == 'February')\n",
    "  ].day.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54a9a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.year.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411259c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.year == 2017].month.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d895918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.year == 2017) &\n",
    "   (df.month == 'November')\n",
    "  ].day.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4487de8b",
   "metadata": {},
   "source": [
    "The reviews span from February 24, 2008 to November 30, 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed8874d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.year.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade1f9a5",
   "metadata": {},
   "source": [
    "## review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f39573",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(df.review[i], '\\n-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3053442f",
   "metadata": {},
   "source": [
    "# language cleaning\n",
    "\n",
    "Before we go any further, we would like to clean up some of the review text. In particular, there are many escaped characters, especially apostrophes.\n",
    "\n",
    "Here is an example of a contraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba94a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.review[3][56:69]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fa5a2b",
   "metadata": {},
   "source": [
    "Here is how the html function fixes it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead7c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "html.unescape(df.loc[3][2])[56:64]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c7fe1c",
   "metadata": {},
   "source": [
    "Here is how the contractions function fixes (the html function's fix of) it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a49b0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions.fix(html.unescape(df.loc[3][2]))[56:65]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f71ebe",
   "metadata": {},
   "source": [
    "Here is an instance of \"ain't\" with the same functions applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf66dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.review.loc[507][75:99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad44b907",
   "metadata": {},
   "outputs": [],
   "source": [
    "html.unescape(df.review.loc[507])[75:94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1badacb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions.fix(html.unescape(df.review.loc[507]))[75:96]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909075f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.review.str.contains('ain&#039;t')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c368c3a",
   "metadata": {},
   "source": [
    "There are 53 instances of \"ain't\".\n",
    "\n",
    "I'm currently having difficulty downloading the package that appropriately fixes \"ain't\" into \"is not\" or \"are not\" etc. This shouldn't matter after I remove stop words. I think it will be helpful to exclude negatives like \"no\" and \"not\" from the stop words. It could certainly be of help to look for bigrams like \"not good\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cee5d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.review = df.review.apply(lambda x: html.unescape(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49f1e72",
   "metadata": {},
   "source": [
    "# missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6962f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition.isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819abf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition.fillna('missing', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1691c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d62807",
   "metadata": {},
   "source": [
    "We noticed another condition label that was meant to indicate missing and should be accordingly changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545fcb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition = df.condition.apply(lambda x: 'missing' if 'Not Listed' in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaddb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ce58e5",
   "metadata": {},
   "source": [
    "We've identified some actual missing condition labels, but we noticed there are more condition labels that seem suspicious, particularly ones that start with something other than an upper case character. Let's look at all such condition labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb02e9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df[(~df.condition.str[0].isin(list(string.ascii_uppercase))) &\n",
    "   (df.condition != 'missing')\n",
    "  ].condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2642fdbf",
   "metadata": {},
   "source": [
    "These fall into three categories. Ones that include \"users found this comment helpful\" should be regarded as erroneous and therefore missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b630c217",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition = df.condition.apply(lambda x: 'missing' if 'users found' in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e1d044",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7629fe29",
   "metadata": {},
   "source": [
    " Ones that show a clipped copy of the drug name and end with a parenthesis should also be regarded as missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6df1dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition = df.condition.apply(lambda x: 'missing' \\\n",
    "                                  if x[0] not in list(string.ascii_uppercase) and \\\n",
    "                                  x[-1] in ['(', ')'] \\\n",
    "                                  else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3777d4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a803d0",
   "metadata": {},
   "source": [
    "# restoring condition labels with errors\n",
    "\n",
    "(skip this step because we're just focusing on birth control?)\n",
    "\n",
    "Most of the ones that show a clipped version of the condition label can possibly be restored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cadb392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition_restore(condition):\n",
    "    if condition.split()[-1] in ['Disorde', 'eve', 'Shoulde', 'Cance']:\n",
    "        condition = condition+'r'\n",
    "    if condition.split()[0] in ['acial', 'ibrocystic', 'ungal', 'amilial', 'ailure', 'ever', \\\n",
    "                                'emale', 'unctional', 'actor', 'ibromyalgia', 'atigue']:\n",
    "        condition = 'F'+condition\n",
    "    if condition.split()[0] in ['llicular', 'llicle', 'lic', 'cal']:\n",
    "        condition = 'Fo'+condition\n",
    "    if condition.split()[0] in ['mance']:\n",
    "        condition = 'Perfor'+condition\n",
    "    if condition.split()[0] in ['zen']:\n",
    "        condition = 'Fro'+condition\n",
    "    if condition.split()[0] in ['mis']:\n",
    "        condition = 'Dermatitis Herpetifor'+condition\n",
    "    return condition\n",
    "\n",
    "df.condition = df.condition.apply(lambda x: condition_restore(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d09bee",
   "metadata": {},
   "source": [
    "Let's look at what we have left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bf43b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df[(~df.condition.str[0].isin(list(string.ascii_uppercase))) &\n",
    "   (df.condition != 'missing')\n",
    "  ].condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0deb45",
   "metadata": {},
   "source": [
    "\"von Willebrand's Disease\" appears to be a naturally uncapitalized condition. The others have been impossible to restore and will also be regarded as missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa9bf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition = df.condition.apply(lambda x: 'missing' \\\n",
    "                                  if x[0] not in list(string.ascii_uppercase) and \\\n",
    "                                  x.split()[0] != 'von' \\\n",
    "                                  else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee8bf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567afaae",
   "metadata": {},
   "source": [
    "We will be able to restore more of these missing condition labels after we do some work with duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef2c0b3",
   "metadata": {},
   "source": [
    "# duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d6b429",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76eeb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb80720",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_review(178703)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f97db7",
   "metadata": {},
   "source": [
    "This is curious. The same review is recorded four times. There are two identical pairs, where the difference between the pairs is the drug name. We can drop one from each pair, but the pairs themselves will need to be revisited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e40916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c19716",
   "metadata": {},
   "source": [
    "# brand / generic pairs\n",
    "\n",
    "The main type of duplicate we should look out for is records with duplicate reviews, as those likely indicate some kind of actual erroneous duplication. Let's see how many of those there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0862c747",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated(subset=['review']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c03ae5",
   "metadata": {},
   "source": [
    "That's a lot!\n",
    "\n",
    "Let's explore some facets of these duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530516d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.duplicated(subset=df.columns.difference(['drugName']))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcb37e8",
   "metadata": {},
   "source": [
    "The vast majority of duplicate reviews are accounted for by different drug names. Let's explore some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac40b129",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated(subset=df.columns.difference(['drugName']))].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c18b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_review(524)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e08bd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_review(574)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c188b0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_review(726)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5a3748",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_review(1070)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8337be7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_review(1375)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a04ef76",
   "metadata": {},
   "source": [
    "These five examples make clear that the vast majority of duplicates are due to double-entry; (nearly) every review is entered once with its generic name and once with its brand name.\n",
    "\n",
    "We can use this phenomenon to restore some of the missing condition labels. If a missing condition label is part of such a unique pair, then we can confidently assign it the condition of its pair-mate.\n",
    "\n",
    "Let's broaden our search to records that duplicate every feature other than drug name and condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b906c6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.duplicated(subset=df.columns.difference(['drugName', 'condition']))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dadae1",
   "metadata": {},
   "source": [
    "This is how many records are duplicates of other records in all values EXCEPT (POSSIBLY) drug name and condition. If a record is duplicated in this manner, the second (and third, fourth, etc.) instance will be captured in this bucket of dupes.\n",
    "\n",
    "If we check only this bucket for dupes, we can see whether there are any triplets, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f93506",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dupes = df[df.duplicated(subset=df.columns.difference(['drugName', 'condition']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70b424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_dupes[df_dupes.duplicated(subset=df_dupes.columns.difference(['drugName', 'condition']))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c1f728",
   "metadata": {},
   "source": [
    "There is only one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b814dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dupes[df_dupes.duplicated(subset=df_dupes.columns.difference(['drugName', 'condition']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c252d85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_review(140144)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3229ac3e",
   "metadata": {},
   "source": [
    "There are 6 records with the same review, date, rating, and condition. Because they're on the *same day*, it seems likely that these reviews were entered repeatedly by the same person. The two with a useful count of 10 are likely a brand/generic pair. As for the other 4, a possible explanation is that Sandostatin and Octreotide are brand names for the two types of insulin, and one of them somehow acquired an erroneous useful count. Let's reassign the useful count of Sandostatin to 3 and let them pair off that way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15359949",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at[133212, 'usefulCount'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb9bbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ⏰ record the time for this cell -- usually 11-12 s\n",
    "\n",
    "# create stripped down dataframe that does not have drug names or conditions\n",
    "# we don't need these features for this operation because we're checking for matches on all other features\n",
    "df_pairs = df.drop(columns=['drugName', 'condition']).copy()\n",
    "\n",
    "# create a list of indices of records that duplicate everything other than drug name and condition\n",
    "df_dupes = df_pairs[df_pairs.duplicated()].index.tolist().copy()\n",
    "\n",
    "# create and populate a dictionary whose keys are dates and values are indices\n",
    "dates_bucket = {}\n",
    "# populate dictionary with keys that are dates belonging to the duplicates\n",
    "for date_ in list(set(df[df.index.isin(df_dupes)].date.tolist())):\n",
    "    dates_bucket[date_] = []\n",
    "# populate dictionary with values that are indices that are NOT from the duplicate list but DO share that date\n",
    "for i in df[~df.index.isin(df_dupes)].index:\n",
    "    dates_bucket[df.loc[i].date].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d6e662",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ⏰ record the time for this cell -- usually 2–4 mins\n",
    "\n",
    "# create a list of record pairs where each entry is a list of two indices\n",
    "pairs = []\n",
    "\n",
    "# iterate over the indices from the dupes list\n",
    "for i in df_dupes:\n",
    "    # set the date to the date from index i\n",
    "    date_i = df.loc[i].date\n",
    "    # iterate over OTHER indices who share that date\n",
    "    for j in dates_bucket[date_i]:\n",
    "        # check for a match\n",
    "        if df_pairs.loc[i].equals(df_pairs.loc[j]):\n",
    "            # remove this index from the dates dictionary so we have fewere to search through in later iterations\n",
    "            dates_bucket[date_i].remove(j)\n",
    "            # add this pair to the pairs list\n",
    "            pairs.append([i,j])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fe8a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b13e28",
   "metadata": {},
   "source": [
    "Let's take a look at several of the pairs we've collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d3a49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9b0998",
   "metadata": {},
   "source": [
    "Here we'll create a dictionary that matches the index of one pair member to the other member of the pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d1eecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_dict = {}\n",
    "\n",
    "for pair in pairs:\n",
    "    for i in range(2):\n",
    "        pairs_dict[pair[i]] = pair[1-i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4883fc3e",
   "metadata": {},
   "source": [
    "# restore missing condition labels\n",
    "\n",
    "We will restore missing condition lables in two ways, in order of certainty:\n",
    "\n",
    "1. For missing values that possess a pair match, we will assign it the condition of its match.\n",
    "2. For the remaining missing values, we will assign it the condition that is most commonly associated with its drug name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaf0b45",
   "metadata": {},
   "source": [
    "First we'll restore missing condition labels for any record that belongs to one of these pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d147a392",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981ff263",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ⏰ record the time for this cell -- usually 15 seconds\n",
    "\n",
    "# iterate over each record pair\n",
    "for pair in pairs:\n",
    "    # iterate over each member of the pair\n",
    "    for i in range(2):\n",
    "        # identify a pair member whose condition is missing\n",
    "        if df.loc[pair[i]].condition == 'missing':\n",
    "            # assign to the pair member the condition of its pair-mate\n",
    "            df.at[pair[i], 'condition'] = df.loc[pairs_dict[pair[i]]].condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337f50b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af5a1cb",
   "metadata": {},
   "source": [
    "We'll make a feature that names the indicated drug and, if applicable, the paired drug.\n",
    "\n",
    "This is not a *final* replacement for the drug name feature, but it will allow us to better recognize the relationship between the generic and brand drug names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3a08fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ⏰ record the time for this cell -- usually 20-30 seconds\n",
    "\n",
    "df['ind'] = df.index\n",
    "\n",
    "def drugList_fix(index, drugName_):\n",
    "    drugList = [drugName_]\n",
    "    if index in pairs_dict:\n",
    "        drugList.append(df.loc[pairs_dict[index]].drugName)\n",
    "        drugList.sort()\n",
    "    return drugList\n",
    "\n",
    "df['drugList'] = df.apply(lambda x: drugList_fix(x.ind, x.drugName), axis=1)\n",
    "\n",
    "df.drop(columns='ind', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59aae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['drugSetString'] = df.drugList.apply(lambda x: x[0] + ' ' + x[1] if len(x) == 2 else x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc56e75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(df[df.duplicated(subset=df.columns.difference(['drugName', 'drugSet', 'drugList']))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544bc6c7",
   "metadata": {},
   "source": [
    "With this new feature in place, we can drop one record from each of the brand/generic pairs. The drug name feature will randomly retain only one member of the pair, which will make this feature more or less useless for the moment.\n",
    "\n",
    "Before we drop these records, we'll create a bookmark copy of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6279e4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bookmark_1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67ebf9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=df.columns.difference(['drugName', 'drugSet', 'drugList']), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a383b4a4",
   "metadata": {},
   "source": [
    "For every remaining record with a missing condition, we will assign it the condition that is most common for the drug indicated by that record. (This will not be biased by duplicates from brand/generic pairs, because we have dropped those duplicates.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467bcecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs_w_missing_condition = list(set(df[df.condition == 'missing'].drugSetString))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4f1e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(drugs_w_missing_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f4c79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drugSetString.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d940073",
   "metadata": {},
   "source": [
    "This applies to some 20% of the drugs. We'll create a dictionary that reports the most common condition for these drugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714f9fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# record the time for this cell -- 10-20 seconds\n",
    "\n",
    "most_common_condition = {}\n",
    "\n",
    "for drug in drugs_w_missing_condition:\n",
    "    condition = df[df.drugSetString == drug].condition.value_counts().idxmax()\n",
    "    if condition == 'missing' and len(set(df[df.drugSetString == drug].condition)) > 1:\n",
    "        condition = df[(df.drugSetString == drug) &\n",
    "                       (df.condition != 'missing')\n",
    "                      ].condition.value_counts().idxmax()\n",
    "    proportion = round(df[df.drugSetString == drug].condition.value_counts(normalize=True)[0],2)\n",
    "    most_common_condition[drug] = [condition, proportion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5472f2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_condition['Sildenafil Viagra']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72221103",
   "metadata": {},
   "source": [
    "For example, if a review with an unlisted condition is about Viagra, we will assume the condition is Erectile \n",
    "Dysfunction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fabcba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f5f9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['condition'] = df.apply(lambda x: most_common_condition[x.drugSetString][0] \\\n",
    "                           if x.condition == 'missing' \\\n",
    "                           else x.condition, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebfffbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f03965",
   "metadata": {},
   "source": [
    "This is how many records there are that still have no condition label. This means the drugs indicated in these records are *only* indicated in references without an indicated condition. As such, there's not really anything we can do with these records, and we may as well drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6541639",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df.condition == 'missing'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f64482",
   "metadata": {},
   "source": [
    "# trim to just birth control\n",
    "\n",
    "At this point, we have decided exactly which records pertain to birth control. Now we can drop all records that pertain to other conditions. We'll make another bookmark copy first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2d1d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bookmark_2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c5f255",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df.condition != 'Birth Control'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5804e789",
   "metadata": {},
   "source": [
    "# exploring generic and brand names\n",
    "\n",
    "Now that we have a smaller number of records to deal with, we can sort out generic and brand names.\n",
    "\n",
    "First we'll create a list of all values from the drug name feature. (Some of these have been dropped from the drug name feature itself, but all of them were included in the drug list feature.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8c13cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs_raw = df.drugList.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ff56ba",
   "metadata": {},
   "source": [
    "Next, we'll create a set of drug names, all of whome appear in a generic/brand pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724fd4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_drug_names = set()\n",
    "\n",
    "for record in drugs_raw:\n",
    "    if len(record) == 2:\n",
    "        all_drug_names.add(record[0])\n",
    "        all_drug_names.add(record[1])\n",
    "\n",
    "len(all_drug_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da87780",
   "metadata": {},
   "source": [
    "Now we'll establish a dictionary whose keys are all the drug names that appear in a generic/brand pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224d04f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_dict = {}\n",
    "\n",
    "for drug in all_drug_names:\n",
    "    drug_dict[drug] = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9ca7e2",
   "metadata": {},
   "source": [
    "We'll assign values to those keys according to the pairings. For example, if drug name A is in a generic/brand pair with drug name B, then they will appear on each other's list of values in this dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e390c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in drugs_raw:\n",
    "    if len(record) == 2:\n",
    "        drug_dict[record[0]].add(record[1])\n",
    "        drug_dict[record[1]].add(record[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ab44f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(drug_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0322dd",
   "metadata": {},
   "source": [
    "Let's find out how many of these drug names are associated with exactly one other drug name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aa67a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for drug in drug_dict:\n",
    "    if len(drug_dict[drug]) == 1:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2698ead8",
   "metadata": {},
   "source": [
    "That should mean that exactly the remainder are associated with multiple drug names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23db1b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for drug in drug_dict:\n",
    "    if len(drug_dict[drug]) > 1:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c328210b",
   "metadata": {},
   "source": [
    "It would make sense that drug names that belong to multiple generic/brand pairs are themselves the generic name. On that assumption, we'll create a list of generic drug names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6b34eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "generics = set()\n",
    "\n",
    "for drug in drug_dict:\n",
    "    if len(drug_dict[drug]) > 1:\n",
    "        generics.add(drug)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa466c2",
   "metadata": {},
   "source": [
    "Now we'll check to make sure that the drug names we've just designated as \"generic\" do NOT belong to a generic/brand pair with *another* \"generic\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa27dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for drug in generics:\n",
    "    for match in drug_dict[drug]:\n",
    "        if match in generics:\n",
    "            print(drug, drug_dict[drug])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7c1df0",
   "metadata": {},
   "source": [
    "Great.\n",
    "\n",
    "Then we can begin designating drug names as \"brands\" if they are in a generic/brand pair with a generic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27615de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands = set()\n",
    "\n",
    "for generic in generics:\n",
    "    for match in drug_dict[generic]:\n",
    "        brands.add(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ef0a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(generics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dba15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(brands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1410c153",
   "metadata": {},
   "source": [
    "Now let's see what drugs remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093f80e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91348984",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(drug for drug in all_drug_names if drug not in generics and drug not in brands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a404b6d",
   "metadata": {},
   "source": [
    "Through this method we have identified some generic names and associated them a greater number of brand names. Together, this accounts for a majority of the drug names. The remaining ones must be unique pairs that only ever appear with each other. We'll need outside information to identify which of these are the generic names and which are the brand names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537caec3",
   "metadata": {},
   "source": [
    "# further exploration of duplicates (skip for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc39d0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.duplicated(subset=['drugName', 'condition', 'rating', 'date'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503ec239",
   "metadata": {},
   "source": [
    "That also seems like a lot. Let's explore these now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e561d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated(subset=['drugName', 'condition', 'rating', 'date'])].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193d65e6",
   "metadata": {},
   "source": [
    "We'll use the \"show_similar\" function to explore these reviews that duplicate drug name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91529b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_similar(2450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92addd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_similar(3597)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ef2ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_similar(4892)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00e991c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated(subset=['drugName', 'condition', 'rating', 'date'])].rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a603a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\n",
    "    (df.drugName == df.loc[8576].drugName) & \\\n",
    "    (df.condition == df.loc[8576].condition) & \\\n",
    "    (df.date == df.loc[8576].date)\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114890fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.drugName == 'Miconazole') & \\\n",
    "   (df.condition == 'Vaginal Yeast Infection') & \\\n",
    "   (df.rating == 1.0) & \\\n",
    "   (df.date == 'May 25, 2016') & \\\n",
    "   (df.usefulCount == 6) \\\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7815e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_review(8737)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e95edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.duplicated(subset=['review'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a34191f",
   "metadata": {},
   "source": [
    "An enormous number of records have duplicated reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa15ec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_review(524)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c915c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_review(574)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee1a4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_review(726)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e53b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_review(1070)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0a6004",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_review(1375)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a277a5c",
   "metadata": {},
   "source": [
    "In all of the instances we checked, the duplicated record occurs because it is listed once under its chemical name and once under its brand name. We'll assume this is mostly the reason for the vast majority of review duplications and deal with them after we address other types of review duplications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dded545",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[(df.duplicated(subset=['review'])) &\n",
    "   ~df.duplicated((['drugName']))\n",
    "  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31cb9b7",
   "metadata": {},
   "source": [
    "This is how many records have identical reviews but differences *other than the drug name*. Let's explore a few of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091adf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.duplicated(subset=['review'])) &\n",
    "   ~df.duplicated(subset=df.columns.difference(['drugName']))\n",
    "  ].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ef345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_review(2664)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d723354",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_review(6465)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8c141e",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_review(9735)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96614fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_review(13125)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b036308f",
   "metadata": {},
   "source": [
    "Some of these are just common, short reviews, e.g. \"Great\". But others seem to have issues with the condition label as well.\n",
    "\n",
    "We found earlier that many duplicate reviews come in pairs where the drug name is generic and brand name in the two records. It seems that more of these pairs exist in instances where the condition is \"missing\" for some reason. Where this specific phenomenon occurs, we'll relabel the condition to match its partner in the pair. This will reduce the number of \"missing\" conditions but increase the number of duplicate pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eabe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb750cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.duplicated(subset=df.columns.difference(['drugName']))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a0e25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.duplicated(subset=df.columns.difference(['condition']))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b1fa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.duplicated(subset=df.columns.difference(['rating']))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f73a7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.duplicated(subset=df.columns.difference(['date']))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceff787",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.duplicated(subset=df.columns.difference(['usefulCount']))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccab4a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated(subset=df.columns.difference(['usefulCount']))].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2ca4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_review(33451)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce22f6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_review(42728)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14988065",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_review(61617)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c3cd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_review(69518)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54f2e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_review(72794)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19aeb860",
   "metadata": {},
   "source": [
    "This appears to be an instance of someone re-posting a review multiple times. It seems that we should drop the duplicates in this case, but possibly we should tally up the useful count?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0944319",
   "metadata": {},
   "source": [
    "# dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b81cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df.date.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78610c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac3f5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.split(r'\\W+', sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f399fc8a",
   "metadata": {},
   "source": [
    "# ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f505f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b19bf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231f9210",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.rating > 8.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0f47b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.rating < 8.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e8a57c",
   "metadata": {},
   "source": [
    "To split the review roughly in half we would split between 8 and 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90cc2c2",
   "metadata": {},
   "source": [
    "To split the ratings roughly in half we would make the splits 1-8 and 9-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d10ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71037c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.rating > 9.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13ef920",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.rating < 6.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be1b66a",
   "metadata": {},
   "source": [
    "To split the ratings roughly in thirds we would make the splits 1-6, 7-9, and 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78754c7d",
   "metadata": {},
   "source": [
    "# focusing on birth control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bbcd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'Birth Control'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e548b82a",
   "metadata": {},
   "source": [
    "This many records pertain to the condition of birth control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e22ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "birth_control_drugs = set(df[df.condition == 'Birth Control'].drugName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b617cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(birth_control_drugs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63c6092",
   "metadata": {},
   "source": [
    "This many drugs treat birth control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6f40e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.condition == 'Birth Control'].drugName.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c018383",
   "metadata": {},
   "source": [
    "These are the most frequent drug names that treat birth control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03aa423",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(df[(df.condition != 'Birth Control') &\n",
    "   (df.drugName.isin(birth_control_drugs))\n",
    "  ].condition))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aba1771",
   "metadata": {},
   "source": [
    "These are other conditions that are (at least sometimes) treated by drugs that (also) treat birth control."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd64752b",
   "metadata": {},
   "source": [
    "# save and reload preprocessed set\n",
    "\n",
    "At this stage we will save and reload the preprocessed set in order to avoid taking the time to repeat earlier work everytime we open the notebook.\n",
    "\n",
    "The saved version has restored or deleted all records with missing condition labels.\n",
    "\n",
    "We have established pairs in the list `twins` but we have NOT yet deleted either member of any pair or dealt with the confusion between brand and generic drug names.\n",
    "\n",
    "The size of the dateframe is nearly the same as its original version, roughly 215,000 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849e0d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = Path('../data/preprocessed.csv')\n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8d8189",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store twins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d37c8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/preprocessed.csv')\n",
    "df.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320eceed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r twins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab319606",
   "metadata": {},
   "source": [
    "# feature engineering ideas\n",
    "\n",
    "- word count\n",
    "- character count\n",
    "- words in all caps\n",
    "- average word length\n",
    "- whether words are in English (spelled correctly)\n",
    "- whether it includes characters such as exclamation points, question marks, (especially repeatedly), and emoticons\n",
    "- whether it mentions the brand or generic name in the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0041207",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'] = df.review.apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf185cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['char_count'] = df.review.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c8dbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "'!' in df.loc[5].review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1b9521",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bookmark_2 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e335d88",
   "metadata": {},
   "source": [
    "# truncate to just birth control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e602178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df.condition != 'Birth Control'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433cb658",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.usefulCount.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde0bd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.usefulCount.quantile(.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f241e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.rating > 8].usefulCount.quantile(.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4aca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.rating < 2].usefulCount.quantile(.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cebf20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c23587d",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_review(17598)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8569eebb",
   "metadata": {},
   "source": [
    "# rudimentary word cloud maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e617e29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1a2ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbc = df[df.condition == 'Birth Control']\n",
    "\n",
    "dfbc['sentiment'] = dfbc.rating.apply(lambda x: 1 if x > 5 else 0)\n",
    "\n",
    "dfbcpos = df[\n",
    "    (df.condition == 'Birth Control') & \\\n",
    "    (df.rating > 9.5)\n",
    "]\n",
    "\n",
    "dfbcneg = df[\n",
    "    (df.condition == 'Birth Control') & \\\n",
    "    (df.rating < 6.5)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a20a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list of all reviews\n",
    "reviews_pos = dfbcpos.review.to_list()\n",
    "reviews_neg = dfbcneg.review.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64952eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make tokenizer\n",
    "# tokenizer = TweetTokenizer(\n",
    "#     preserve_case=False,\n",
    "#     strip_handles=True\n",
    "# )\n",
    "\n",
    "# create list of tokens from data set\n",
    "tokens_pos = word_tokenize(','.join(reviews_pos))\n",
    "tokens_neg = word_tokenize(','.join(reviews_neg))\n",
    "\n",
    "\n",
    "# tokens = [word for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d571240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# lemmatize the list of words\n",
    "tokens_lemmatized_pos = [lemmatizer.lemmatize(word) for word in tokens_pos]\n",
    "tokens_lemmatized_neg = [lemmatizer.lemmatize(word) for word in tokens_neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e518436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the most frequently occurring tokens\n",
    "FreqDist(tokens_lemmatized_pos).most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c65aa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the most frequently occurring tokens\n",
    "FreqDist(tokens_lemmatized_neg).most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70924a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives = ['no', 'not', \"don't\", \"aren't\", \"couldn't\", \"didn't\", \"doesn't\", \"hadn't\", \"hasn't\", \"haven't\", \\\n",
    "             \"isn't\", \"wasn't\", \"weren't\", \"won't\", \"wouldn't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649e4fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the standard list of stopwords\n",
    "nltk.download('stopwords', quiet=True)\n",
    "# start our own list of stopwords with these words\n",
    "stop_list = [word for word in stopwords.words('english') if word not in negatives]\n",
    "# add punctuation characters\n",
    "for char in string.punctuation:\n",
    "    stop_list.append(char)\n",
    "# add empty string\n",
    "stop_list.extend(['', 'ha', 'wa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3882f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c713b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make stopped list of tokens\n",
    "tokens_stopped_pos = [word for word in tokens_lemmatized_pos if word not in stop_list]\n",
    "tokens_stopped_neg = [word for word in tokens_lemmatized_neg if word not in stop_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c38972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the most frequently occurring tokens\n",
    "FreqDist(tokens_stopped_pos).most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cd19f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the most frequently occurring tokens\n",
    "FreqDist(tokens_stopped_neg).most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba7960f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that generates a word cloud of a given list of words\n",
    "def make_wordcloud(wordlist, colormap='Greens', title=None):\n",
    "    # instantiate wordcloud\n",
    "    wordcloud = WordCloud(\n",
    "        width=600,\n",
    "        height=400,\n",
    "        colormap=colormap,\n",
    "        collocations = True\n",
    "    )\n",
    "    return wordcloud.generate(','.join(wordlist))\n",
    "\n",
    "def plot_wordcloud(wordcloud):\n",
    "    # plot wordcloud\n",
    "    plt.figure(figsize = (12, 15)) \n",
    "    plt.imshow(wordcloud) \n",
    "    plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa9db94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word cloud of stopped words\n",
    "plot_wordcloud(make_wordcloud(tokens_stopped_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b644b2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word cloud of stopped words\n",
    "plot_wordcloud(make_wordcloud(tokens_stopped_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be12b22",
   "metadata": {},
   "source": [
    "# end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
