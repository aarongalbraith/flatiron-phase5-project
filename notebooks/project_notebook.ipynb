{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0aaedc3",
   "metadata": {},
   "source": [
    "# Flatiron Phase 5 Project\n",
    "\n",
    "## Aaron Galbraith\n",
    "\n",
    "https://www.linkedin.com/in/aarongalbraith \\\n",
    "https://github.com/aarongalbraith\n",
    "\n",
    "### Submitted: November 20, 2023\n",
    "\n",
    "## Contents\n",
    "\n",
    "- **[Business Understanding](#Business-Understanding)<br>**\n",
    "- **[Data Understanding](#Data-Understanding)**<br>\n",
    "- **[Data Preparation](#Data-Preparation)**<br>\n",
    "- **[Exploration](#Exploration)**<br>\n",
    "- **[Modeling](#Modeling)**<br>\n",
    "- **[Evaluation](#Evaluation)**<br>\n",
    "- **[Recommendations](#Recommendations)<br>**\n",
    "- **[Further Inquiry](#Further-Inquiry)**<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a829ef",
   "metadata": {},
   "source": [
    "# Business Understanding\n",
    "\n",
    "In 2022 the US Supreme Court ruled in [Dobbs v. Jackson Women's Health Organization](https://www.supremecourt.gov/opinions/21pdf/19-1392_6j37.pdf) that the United States Constitution would no longer confer a right to abortion and that the legality of abortion timelines and procedures would be at the discretion of the individual states and territories. This brought an end to constitutionally enshrined abortion access after Americans had been guaranteed such rights in all American states and territories for roughly two generations, since the 1973 ruling in [Roe v. Wade](https://tile.loc.gov/storage-services/service/ll/usrep/usrep410/usrep410113/usrep410113.pdf). Both immediately and in the short time since the Dobbs decision, [many states have reduced access to abortion, and 14 states have banned abortion entirely](https://reproductiverights.org/maps/abortion-laws-by-state/). [Advocates for birth control access fear that new government controls could move beyond abortion and attempt to restrict birth control access as well](https://www.npr.org/2022/08/16/1117615628/abortion-birth-control-title-x-supreme-court-family-planning-planned-parenthood).\n",
    "\n",
    "In the new reproductive environment created by this ruling, Americans who are concerned with family planning need to be better informed of their changing options. They can learn a lot from one another by comparing their experiences with different treatments. This is especially crucial in communities where birth control practices are discouraged and some young people in particular may be less informed about birth control methods, their efficacy, and their side effects. Reproductive health advocacy groups such as Planned Parenthood will likely play an even greater role in this new environment.\n",
    "\n",
    "In 2018, researchers Surya Kallumadi and Felix Gräßer at UC Irvine created the [UCI ML Drug Review dataset](https://www.kaggle.com/datasets/jessicali9530/kuc-hackathon-winter-2018/) after collecting reviews from [Drugs.com](https://www.drugs.com/) that users had written about various drugs between 2008 and 2017. A substantial portion of these reviews addressed birth control and emergency contraception drugs. Each review was accompanied by a user rating and a tally of how many other users found the review useful (\"upvotes\").\n",
    "\n",
    "Our project seeks to use this data in any way that informs and serves those in need of reproductive health care. Our analysis of this data can help inform people about which birth control options are seen by users as the most effective and what side effects are commonly associated with them. We can also apply our rating prediction algorithm to analyze discussions — particularly anonymous ones – in online forums such as [Reddit](https://www.reddit.com/r/birthcontrol/) and [Quora](https://www.quora.com/search?q=birth%20control) without formal ratings systems to detect commenters' sentiment toward and experience with various contraceptive methods. This can help organizations such as Planned Parenthood detect prevalent opinions, preferences and concerns that might not otherwise be available to them through traditional patient feedback mechanisms. Thus informed, Planned Parenthood can respond to their patients' concerns before they even arise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27e0077",
   "metadata": {},
   "source": [
    "# Data Understanding\n",
    "\n",
    "## Import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c42b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import html\n",
    "import contractions\n",
    "\n",
    "import re\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "SEED = 1979\n",
    "\n",
    "do_grids = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08955966",
   "metadata": {},
   "source": [
    "## Load and briefly explore data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea141bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.read_csv('../data/drugsComTrain_raw.tsv', delimiter='\\t', encoding='latin-1')\n",
    "d2 = pd.read_csv('../data/drugsComTest_raw.tsv', delimiter='\\t', encoding='latin-1')\n",
    "df = pd.concat([d1,d2]).reset_index().drop(columns=['Unnamed: 0', 'index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777ba6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e39110",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603356ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47187984",
   "metadata": {},
   "source": [
    "There are some missing `condition` labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0575802f",
   "metadata": {},
   "source": [
    "### `drugName` feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40b36d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drugName.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5063aa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drugName.value_counts().quantile(.90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dc92f3",
   "metadata": {},
   "source": [
    "There are 3,671 unique drug names, and 10% of the drug names have more than 120 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f6a9e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "print(df.drugName.value_counts())\n",
    "pd.set_option(\"display.max_rows\", 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f79d7c",
   "metadata": {},
   "source": [
    "A casual overview of the drug names indicates that they all seem valid. Some seem to specify drug combinations and/or dosage amounts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34af70c1",
   "metadata": {},
   "source": [
    "### `condition` feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad487ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a92693",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition.value_counts().quantile(.90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f04ae38",
   "metadata": {},
   "source": [
    "There are 916 unique conditions, and 10% of the conditions have more than 332 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651541e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "print(df.condition.value_counts())\n",
    "pd.set_option(\"display.max_rows\", 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6261d028",
   "metadata": {},
   "source": [
    "Oddly, the condition labels often (always?) omit initial 'F' and terminal 'r'. We can isolate instances of the former by searching for conditions that start with a lower case letter.\n",
    "\n",
    "We will eventually trim our records to a number of conditions that Planned Parenthood specializes in treating (and perhaps birth control exclusively), but we will need all the records to help us determine missing condition labels. After we have restored (or discarded) all missing condition labels, we can drop the conditions outside the scope of this review."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fdaf8c",
   "metadata": {},
   "source": [
    "### `drugName` × `condition` features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df995543",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('drugName').condition.nunique().value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f2a4d4",
   "metadata": {},
   "source": [
    "This means that, for example, 1869 drugs treat 1 condition only, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c6c03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('condition').drugName.nunique().value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab49148",
   "metadata": {},
   "source": [
    "This means that 188 conditions are treatable by two drugs, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d28e78",
   "metadata": {},
   "source": [
    "### `review` feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3d03d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.review.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9a1f88",
   "metadata": {},
   "source": [
    "This suggests that just over half of the review values are unique. Almost certainly there will be some duplication issues to deal with.\n",
    "\n",
    "Let's look at several reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b43138",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(df.review[i], '\\n-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2098ffb",
   "metadata": {},
   "source": [
    "There appear to be escaped characters (e.g. `&#039;`, indicating an apostrophe) and contractions. We can address this now without affecting our analysis.\n",
    "\n",
    "We'll reset the review texts to unescape these characters and expand all contractions.\n",
    "\n",
    "Note: This will replace all instances of `ain't` with `are not`, resulting in some subject-verb agreement issues (e.g. `I are not`). This difference will be negligible in our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6d29d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.review = df.review.apply(lambda x: contractions.fix(html.unescape(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc61817",
   "metadata": {},
   "source": [
    "### `rating` feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3464a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749ea1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rating.hist(bins=df.rating.nunique());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d64996",
   "metadata": {},
   "source": [
    "Most of the conditions lie at the extremes, and more of them appear to be at the positive extreme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e73e47",
   "metadata": {},
   "source": [
    "### `date` feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c727ea03",
   "metadata": {},
   "source": [
    "In order to get a better understanding of the `date` feature, we'll convert it to a `datetime` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb711c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['datetime'] = df.date.apply(lambda x: datetime.strptime(x, '%B %d, %Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4829300b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.datetime.hist(bins=80);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d71be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = df.datetime.min().strftime('%B %d, %Y')\n",
    "end_date = df.datetime.max().strftime('%B %d, %Y')\n",
    "\n",
    "print('The reviews span specifically from', start_date+',', 'to', end_date+'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81525267",
   "metadata": {},
   "source": [
    "The reviews began to surge in early 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d72ad53",
   "metadata": {},
   "source": [
    "### `usefulCount` feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b07a0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "usefulCountCumulative = list(df.usefulCount.values)\n",
    "usefulCountCumulative.sort(reverse=True)\n",
    "\n",
    "X = range(0,len(df),5000)\n",
    "Y = []\n",
    "for x in X:\n",
    "    Y.append(sum(usefulCountCumulative[:x]))\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(X,Y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710ca66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.usefulCount.value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a097e044",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba05f590",
   "metadata": {},
   "source": [
    "## Missing and erroneous condition labels\n",
    "\n",
    "In this section we will identify all `condition` labels that are either missing or in need of editing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefd19a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition.isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16903a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition.fillna('missing', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98620ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18571e4",
   "metadata": {},
   "source": [
    "We noticed another `condition` label that was meant to indicate missing and should be accordingly changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6765cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition = df.condition.apply(lambda x: 'missing' if 'Not Listed' in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d3c8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425d0ebe",
   "metadata": {},
   "source": [
    "We've identified some actual missing `condition` labels, but we noticed there are more `condition` labels that seem suspicious, particularly ones that start with something other than an upper case character. Let's look at all such `condition` labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adcafd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df[(~df.condition.str[0].isin(list(string.ascii_uppercase))) &\n",
    "   (df.condition != 'missing')\n",
    "  ].condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a774b557",
   "metadata": {},
   "source": [
    "These fall into three categories:\n",
    "1. \"X users found this comment helpful\" should be regarded as an erroneous label and retagged as \"missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68cb5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition = df.condition.apply(lambda x: 'missing' if 'users found' in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efa2a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea88aaa4",
   "metadata": {},
   "source": [
    "2. Labels that show a clipped copy of the `drugName` label and end with a parenthesis should also be regarded as missing. These erroneous labels merely repeat information already available in the `drugName` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f508cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition = df.condition.apply(lambda x: 'missing' \\\n",
    "                                  if x[0] not in list(string.ascii_uppercase) and \\\n",
    "                                  x[-1] in ['(', ')'] \\\n",
    "                                  else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf534298",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8ffe3a",
   "metadata": {},
   "source": [
    "3. Other `condition` labels appear to omit the first and/or last several characters. We can infer certain corrections here to restore many of the conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049d3851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition_restore(condition):\n",
    "    if condition.split()[-1] in ['Disorde', 'eve', 'Shoulde', 'Cance']:\n",
    "        condition = condition+'r'\n",
    "    if condition.split()[0] in ['acial', 'ibrocystic', 'ungal', 'amilial', 'ailure', 'ever', \\\n",
    "                                'emale', 'unctional', 'actor', 'ibromyalgia', 'atigue']:\n",
    "        condition = 'F'+condition\n",
    "    if condition.split()[0] in ['llicular', 'llicle', 'lic', 'cal']:\n",
    "        condition = 'Fo'+condition\n",
    "    if condition.split()[0] in ['mance']:\n",
    "        condition = 'Perfor'+condition\n",
    "    if condition.split()[0] in ['zen']:\n",
    "        condition = 'Fro'+condition\n",
    "    if condition.split()[0] in ['mis']:\n",
    "        condition = 'Dermatitis Herpetifor'+condition\n",
    "    return condition\n",
    "\n",
    "df.condition = df.condition.apply(lambda x: condition_restore(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588b1d0d",
   "metadata": {},
   "source": [
    "Let's look at what we have left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036c4523",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df[(~df.condition.str[0].isin(list(string.ascii_uppercase))) &\n",
    "   (df.condition != 'missing')\n",
    "  ].condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d1b133",
   "metadata": {},
   "source": [
    "\"von Willebrand's Disease\" appears to be a naturally uncapitalized condition. The others have been impossible to restore and will also be regarded as missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32b491b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition = df.condition.apply(lambda x: 'missing' \\\n",
    "                                  if x[0] not in list(string.ascii_uppercase) and \\\n",
    "                                  x.split()[0] != 'von' \\\n",
    "                                  else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a2c264",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e15aea",
   "metadata": {},
   "source": [
    "We will be able to restore more of these missing condition labels after we do some work with duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d4f414",
   "metadata": {},
   "source": [
    "## Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c54a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e05b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5652a75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_duplicates = True\n",
    "\n",
    "def show_review(index):\n",
    "    if show_duplicates:\n",
    "        display(df[df.review == df.loc[index].review][['drugName', 'condition', 'rating', 'date', 'usefulCount']])\n",
    "    print('\\nReview #'+str(index),'| Rating:',df.loc[index].rating,'| Upvotes:',\n",
    "          df.loc[index].usefulCount,'\\n\\n'+df.review.loc[index][1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fc3ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_review(178703)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d47b79",
   "metadata": {},
   "source": [
    "For reasons we will explore later, we believe this review was submitted twice by the same person, that each instance of it happened to receive 10 upvotes, and that it should correctly be associated with a grand total of 20 upvotes. Because this is one special instance where the review happened to receive 10 upvotes both times, making it a true duplicate of the data set, we will fix the values here, lest it interfere with operations later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddf9e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at[178703, 'usefulCount'] = 20\n",
    "df.at[191001, 'usefulCount'] = 20\n",
    "df.drop([131531, 143768], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f89b63",
   "metadata": {},
   "source": [
    "## Duplicates due to brand / generic pairs\n",
    "\n",
    "The main type of duplicate we should look out for is records with duplicate reviews, as those likely indicate some kind of actual erroneous duplication. Let's see how many of those there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad317e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated(subset=['review']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e038de",
   "metadata": {},
   "source": [
    "That's a lot!\n",
    "\n",
    "Let's explore some facets of these duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0c558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.duplicated(subset=df.columns.difference(['drugName']))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce282d5",
   "metadata": {},
   "source": [
    "The vast majority of duplicate reviews are accounted for by different drug names. Let's explore some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d27b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in df[df.duplicated(subset=df.columns.difference(['drugName']))].index[:5]:\n",
    "    show_review(ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de187e82",
   "metadata": {},
   "source": [
    "These five examples make clear that the vast majority of duplicates are due to double-entry; (nearly) every review is entered once with its generic name and once with its brand name.\n",
    "\n",
    "We can use this phenomenon to restore some of the missing condition labels. If a missing condition label is part of such a unique pair, then we can confidently assign it the condition of its pair-mate.\n",
    "\n",
    "Let's broaden our search to records that duplicate every feature other than drug name and condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bcdf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.duplicated(subset=df.columns.difference(['drugName', 'condition']))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fedda3",
   "metadata": {},
   "source": [
    "This is how many records are duplicates of other records in all values EXCEPT (POSSIBLY) drug name and condition. If a record is duplicated in this manner, the second (and third, fourth, etc.) instance will be captured in this bucket of dupes.\n",
    "\n",
    "If we check only this bucket for dupes, we can see whether there are any triplets, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3e7212",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dupes = df[df.duplicated(subset=df.columns.difference(['drugName', 'condition']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279f6c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_dupes[df_dupes.duplicated(subset=df_dupes.columns.difference(['drugName', 'condition']))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa18e11d",
   "metadata": {},
   "source": [
    "There is only one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfbd2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dupes[df_dupes.duplicated(subset=df_dupes.columns.difference(['drugName', 'condition']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60179ad7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_review(140144)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aab57d0",
   "metadata": {},
   "source": [
    "There are 6 records with the same review, date, rating, and condition. (The reviews on October 5, 2012, appear to be just a coincidence of the same review wording for a different drug and condition.) Because they're on the *same day*, it seems likely that these reviews were possibly entered repeatedly by the same person. The two with a useful count of 10 are likely a brand/generic pair.\n",
    "\n",
    "As for the other 4, it's not clear what is going on. We will (would) later discover that there is also some discrepancy as to which of these is a brand or generic name. Since the review text isn't very descriptive, and the useful count is so low, (and it doesn't pertain to the main conditions treated by Planned Parenthood), let's just drop all 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a4ab87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([60998, 119972, 133212, 140144], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0c6b9f",
   "metadata": {},
   "source": [
    "Now we should be able to create a list of pairs of indices of records that match in all features except possibly drug name and condition. To make this run faster, we'll first create a way to sort them by date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4472cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ⏰ record the time for this cell -- usually 11-12 s\n",
    "\n",
    "# create stripped down dataframe that does not have drug names or conditions\n",
    "# we don't need these features for this operation because we're checking for matches on all other features\n",
    "df_pairs = df.drop(columns=['drugName', 'condition']).copy()\n",
    "\n",
    "# create a list of indices of records that duplicate everything other than drug name and condition\n",
    "df_dupes = df_pairs[df_pairs.duplicated()].index.tolist().copy()\n",
    "\n",
    "# create and populate a dictionary whose keys are dates and whose values are indices\n",
    "dates_dict = {}\n",
    "# populate dictionary with keys that are dates belonging to the duplicates\n",
    "for date_ in list(set(df[df.index.isin(df_dupes)].date.tolist())):\n",
    "    dates_dict[date_] = []\n",
    "# populate dictionary with values that are indices that are NOT from the duplicate list but DO share that date\n",
    "for i in df[~df.index.isin(df_dupes)].index:\n",
    "    dates_dict[df.loc[i].date].append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8544b539",
   "metadata": {},
   "source": [
    "Now we can use this dates dictionary to sort and identify the pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cb2149",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ⏰ record the time for this cell -- usually 2–4 mins\n",
    "\n",
    "# create a list of record pairs where each entry is a list of two indices\n",
    "pairs = []\n",
    "\n",
    "# iterate over the indices from the dupes list\n",
    "for i in df_dupes:\n",
    "    # set the date to the date from index i\n",
    "    date_i = df.loc[i].date\n",
    "    # iterate over OTHER indices who share that date\n",
    "    for j in dates_dict[date_i]:\n",
    "        # check for a match\n",
    "        if df_pairs.loc[i].equals(df_pairs.loc[j]) and df.drugName.loc[i] != df.drugName.loc[j]:\n",
    "            # remove this index from the dates dictionary so we have fewer to search through in later iterations\n",
    "            dates_dict[date_i].remove(j)\n",
    "            # add this pair to the pairs list\n",
    "            pairs.append([i,j])\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c838e239",
   "metadata": {},
   "source": [
    "Let's take a look at several of the pairs we've collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f68bc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37cbc1f",
   "metadata": {},
   "source": [
    "Here we'll create a dictionary that matches the index of one pair member to the other member of the pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad35d9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_dict = {}\n",
    "\n",
    "for pair in pairs:\n",
    "    for i in range(2):\n",
    "        pairs_dict[pair[i]] = pair[1-i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed522b3d",
   "metadata": {},
   "source": [
    "## Restore missing `condition` labels\n",
    "\n",
    "We will restore missing `condition` labels in two ways, in order of certainty:\n",
    "\n",
    "1. For missing values that possess a pair match, we will assign it the condition of its match.\n",
    "2. For the remaining missing values, we will assign it the condition that is most commonly associated with its drug name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08d4cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6feb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ⏰ record the time for this cell -- usually 10-15 seconds\n",
    "\n",
    "# iterate over each record pair\n",
    "for pair in pairs:\n",
    "    # iterate over each member of the pair\n",
    "    for i in range(2):\n",
    "        # identify a pair member whose condition is missing\n",
    "        if df.loc[pair[i]].condition == 'missing':\n",
    "            # assign to the pair member the condition of its pair-mate\n",
    "            df.at[pair[i], 'condition'] = df.loc[pairs_dict[pair[i]]].condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e39cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b74fec",
   "metadata": {},
   "source": [
    "Because it will be useful later, we'll make a feature that names the indicated drug and, if applicable, the paired drug.\n",
    "\n",
    "This is not a *final* replacement for the drug name feature, but it will allow us to better recognize the relationship between the generic and brand drug names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0363fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ⏰ record the time for this cell -- usually 15-30 seconds\n",
    "\n",
    "df['ind'] = df.index\n",
    "\n",
    "def drugList_fix(index, drugName_):\n",
    "    drugList = [drugName_]\n",
    "    if index in pairs_dict:\n",
    "        drugList.append(df.loc[pairs_dict[index]].drugName)\n",
    "        # alphabetize each drug pair so that we will not mistakenly duplicate e.g. [A,B] & [B,A]\n",
    "        drugList.sort()\n",
    "    return drugList\n",
    "\n",
    "df['drugList'] = df.apply(lambda x: drugList_fix(x.ind, x.drugName), axis=1)\n",
    "\n",
    "df.drop(columns='ind', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85608bb",
   "metadata": {},
   "source": [
    "Now we can create a feature that tells us if a record is associated with a paired drug name or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a6b4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['isPaired'] = df.drugList.apply(lambda x: True if len(x) > 1 else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2cf5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.isPaired])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b081e541",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[~df.isPaired])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ea4dbc",
   "metadata": {},
   "source": [
    "Because lists confuse certain operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98303056",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['drugSetString'] = df.drugList.apply(lambda x: x[0] + ' ' + x[1] if len(x) == 2 else x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c933b2b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(df[df.duplicated(subset=df.columns.difference(['drugName', 'drugSet', 'drugList']))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe6bd47",
   "metadata": {},
   "source": [
    "With this new feature in place, we can drop one record from each of the brand/generic pairs. The drug name feature will retain only one member of the pair -- unpredictably either the brand or the generic -- which will make this feature more or less useless for the moment.\n",
    "\n",
    "Before we drop these records, we'll create a bookmark copy of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060c4eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT re-run this cell out of sequence\n",
    "# to use the dataframe as it was at this stage, un-comment, run, and re-comment the cell that follows after it.\n",
    "df_bookmark_1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46f2265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df_bookmark_1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3104bb88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=df.columns.difference(['drugName', 'drugSet', 'drugList']), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1b022b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_duplicates = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a29501",
   "metadata": {},
   "source": [
    "For every remaining record with a missing condition, we will assign it the condition that is most common for the drug indicated by that record. (This will not be biased by duplicates from brand/generic pairs, because we have dropped those duplicates.)\n",
    "\n",
    "This will be the last use we have for conditions *not* treated by Planned Parenthood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894d6f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs_w_missing_condition = list(set(df[df.condition == 'missing'].drugSetString))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f60075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(drugs_w_missing_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8046cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drugSetString.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5b7144",
   "metadata": {},
   "source": [
    "This applies to some 20% of the drugs. We'll create a dictionary that reports the most common condition for these drugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5220d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# record the time for this cell -- 10-20 seconds\n",
    "\n",
    "most_common_condition = {}\n",
    "\n",
    "for drug in drugs_w_missing_condition:\n",
    "    condition = df[df.drugSetString == drug].condition.value_counts().idxmax()\n",
    "    if condition == 'missing' and len(set(df[df.drugSetString == drug].condition)) > 1:\n",
    "        condition = df[(df.drugSetString == drug) &\n",
    "                       (df.condition != 'missing')\n",
    "                      ].condition.value_counts().idxmax()\n",
    "    proportion = round(df[df.drugSetString == drug].condition.value_counts(normalize=True)[0],2)\n",
    "    most_common_condition[drug] = [condition, proportion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c9f7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_condition['Sildenafil Viagra']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596d5f89",
   "metadata": {},
   "source": [
    "For example, if a review with an unlisted condition is about Viagra, we will assume the condition is Erectile \n",
    "Dysfunction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13103f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3968373b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['condition'] = df.apply(lambda x: most_common_condition[x.drugSetString][0] \\\n",
    "                           if x.condition == 'missing' \\\n",
    "                           else x.condition, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc122de",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f226f8d2",
   "metadata": {},
   "source": [
    "This is how many records there are that still have no condition label. This means the drugs indicated in these records are *only* indicated in references without an indicated condition. As such, there's not really anything we can do with these records, and we may as well drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4227aed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df.condition == 'missing'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001b21e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802b09c6",
   "metadata": {},
   "source": [
    "## Drop records by condition\n",
    "\n",
    "At this point, we still have more cleaning to do, but we have identified all the conditions that we can, and we won't have any further need for records with certain condition values, so we'll drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48fc37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT re-run this cell out of sequence\n",
    "# to use the dataframe as it was at this stage, un-comment, run, and re-comment the cell that follows after it.\n",
    "df_bookmark_2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feed73d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df_bookmark_2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffe0d41",
   "metadata": {},
   "source": [
    "Let's take another look at the complete list of conditions and choose which ones to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be466edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225f54dc",
   "metadata": {},
   "source": [
    "Since there are so many conditions to consider, let's limit this to just conditions with at least 25 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65079e64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "display(df['condition'].value_counts().loc[lambda x: x >= 25])\n",
    "pd.set_option(\"display.max_rows\", 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d476bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[~df.condition.isin(['Birth Control', 'Emergency Contraception'])].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ab2131",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1112d8e",
   "metadata": {},
   "source": [
    "## Pairing generic and brand names\n",
    "\n",
    "Now that we have a smaller number of records to deal with, we can sort out generic and brand names.\n",
    "\n",
    "First we'll create a list of all values from the drug name feature. (Some of these have been dropped from the drug name feature itself when we dropped one record from each brand/generic pair, but all of them were included in the drug list feature.)\n",
    "\n",
    "We'll create two lists: paired drugs (which we will attempt to sort into brand and generic) and single drugs (each of which we will then try to identify as either brand or generic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d330769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3658c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_drug_lists = df.drugList.tolist()\n",
    "all_drug_lists.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54bd7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_drug_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ec370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_drug_names = set()\n",
    "\n",
    "for list_ in all_drug_lists:\n",
    "    all_drug_names.add(list_[0])\n",
    "    if len(list_) > 1:\n",
    "        all_drug_names.add(list_[1])\n",
    "\n",
    "all_drug_names = list(all_drug_names)\n",
    "\n",
    "all_drug_names.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf4b0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_drug_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e39616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will create a full list with duplicates\n",
    "# we need to do this intermediate before moving to the following step to remove duplicates\n",
    "paired_drug_lists = df[df.isPaired].drugList.tolist()\n",
    "paired_drug_lists.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21357022",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(paired_drug_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad931ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_drug_names = set()\n",
    "\n",
    "for pair in paired_drug_lists:\n",
    "    paired_drug_names.add(pair[0])\n",
    "    paired_drug_names.add(pair[1])\n",
    "\n",
    "paired_drug_names = list(paired_drug_names)\n",
    "\n",
    "paired_drug_names.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc79baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "unpaired_drug_names = [drug for drug in all_drug_names if drug not in paired_drug_names]\n",
    "\n",
    "unpaired_drug_names.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42549a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(paired_drug_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30089b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unpaired_drug_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbdd460",
   "metadata": {},
   "source": [
    "Together, these two lists of names constitute all the drug names left to sort into brand and generic categories.\n",
    "\n",
    "In order to sort the list of paired drugs into brand and generic, we'll establish a dictionary whose keys are all the drug names that appear in a generic/brand pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2890c7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_dict = {}\n",
    "\n",
    "for drug in paired_drug_names:\n",
    "    drug_dict[drug] = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e80bf1e",
   "metadata": {},
   "source": [
    "We'll assign values to those keys according to the pairings. For example, if drug name A is in a generic/brand pair with drug name B, then they will appear on each other's list of values in this dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a823da96",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in paired_drug_lists:\n",
    "    drug_dict[pair[0]].add(pair[1])\n",
    "    drug_dict[pair[1]].add(pair[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca93c8b",
   "metadata": {},
   "source": [
    "Let's find out how many of these drug names are associated with exactly one other drug name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7662e27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len({drug for drug in drug_dict if len(drug_dict[drug]) == 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5fb607",
   "metadata": {},
   "source": [
    "That should mean that exactly the remainder are associated with multiple drug names. It would make sense that drug names that belong to multiple generic/brand pairs are themselves the generic name. On that assumption, we'll create a list of generic drug names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dee795b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generics = [drug for drug in drug_dict if len(drug_dict[drug]) > 1]\n",
    "\n",
    "generics.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0d9469",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(generics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc53676",
   "metadata": {},
   "source": [
    "Now we'll check to make sure that the drug names we've just designated as \"generic\" do NOT belong to a generic/brand pair with *another* \"generic\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50061114",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for drug in generics:\n",
    "    for match in drug_dict[drug]:\n",
    "        if match in generics:\n",
    "            count += 1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f132e0b",
   "metadata": {},
   "source": [
    "Great.\n",
    "\n",
    "Then we can begin designating drug names as \"brands\" if they are in a generic/brand pair with a generic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fd4234",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands = set()\n",
    "\n",
    "for generic in generics:\n",
    "    for match in drug_dict[generic]:\n",
    "        brands.add(match)\n",
    "\n",
    "brands = list(brands)\n",
    "\n",
    "brands.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fbba21",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(brands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00014f7c",
   "metadata": {},
   "source": [
    "Now let's see what drugs remain and how many records they are associated with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed58e423",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncategorized = list(set(drug for drug in paired_drug_names if drug not in generics and drug not in brands))\n",
    "\n",
    "uncategorized.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef54235",
   "metadata": {},
   "source": [
    "To be clear, these are drug names with the following properties:\n",
    "\n",
    "- the drug name belongs to an exclusive brand/generic pair\n",
    "- we have not yet identified which members of the pair are brand and generic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1259cecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(uncategorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bbf7b2",
   "metadata": {},
   "source": [
    "We should be able to list all of these drug names in their pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b639e96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated = set()\n",
    "for drug in uncategorized:\n",
    "    if drug not in repeated:\n",
    "        print(drug, '||', list(drug_dict[drug])[0])\n",
    "        repeated.add(drug)\n",
    "        repeated.add(list(drug_dict[drug])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a055a24",
   "metadata": {},
   "source": [
    "With so few pairs, we can Google the names to determine which names of a pair are generic and brand names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f81dfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_brands = [\n",
    "#     'Clomid', 'Premarin', 'ParaGard', 'Natazia', 'NuvaRing', 'Femara', \\\n",
    "#     'Glucophage', 'Lysteda', 'Megace', 'Necon 1 / 50', 'ella'\n",
    "# ]\n",
    "\n",
    "# brands.extend(new_brands)\n",
    "\n",
    "# len(brands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237485dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_brands = [\n",
    "    'ParaGard', 'Natazia', 'NuvaRing', 'Necon 1 / 50', 'ella'\n",
    "]\n",
    "\n",
    "brands.extend(new_brands)\n",
    "\n",
    "len(brands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868f4a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "for drug in new_brands:\n",
    "    generics.append(list(drug_dict[drug])[0])\n",
    "\n",
    "len(generics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e5c626",
   "metadata": {},
   "source": [
    "At this point, we have sorted all the paired brand and generic drug names. What remains is to identify whether each of the single drug names is a generic or brand name.\n",
    "\n",
    "Let's look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666f2b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unpaired_drug_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b968c0",
   "metadata": {},
   "source": [
    "Simple Google search confirms these are both generic names, so we'll add them as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222d57c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "generics.extend(unpaired_drug_names)\n",
    "\n",
    "generics.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce3a193",
   "metadata": {},
   "source": [
    "Now we create a more universal drug naming system whereby every record is identified with its generic name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8282cf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic_fix(drugList):\n",
    "    if len(drugList) == 1 or drugList[0] in generics:\n",
    "        return drugList[0]\n",
    "    else:\n",
    "        return drugList[1]\n",
    "\n",
    "df['genericName'] = df.drugList.apply(lambda x: generic_fix(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7eff93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_brand_fix(drugList):\n",
    "    if len(drugList) == 1:\n",
    "        return None\n",
    "    elif drugList[0] in brands:\n",
    "        return drugList[0]\n",
    "    else:\n",
    "        return drugList[1]\n",
    "\n",
    "df['fullBrandName'] = df.drugList.apply(lambda x: full_brand_fix(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e3ffa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_dict = {}\n",
    "\n",
    "for fullName in brands:\n",
    "    name = fullName\n",
    "    tail = name.split()[-1]\n",
    "    while tail.isnumeric() or tail in ['Fe', 'Lo', 'One-Step', '/', '1.5', 'Contraceptive']:\n",
    "        name = name[:len(name)-len(tail)-1]\n",
    "        tail = name.split()[-1]\n",
    "    head = name.split()[0]\n",
    "    while head in ['Lo', '/']:\n",
    "        name = name[len(head)+1:]\n",
    "        head = name.split()[0]\n",
    "    brand_dict[fullName] = name\n",
    "\n",
    "df['shortBrandName'] = df.fullBrandName.apply(lambda x: None if x == None else brand_dict[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722af77e",
   "metadata": {},
   "source": [
    "## Duplicates due to multiple user entry\n",
    "\n",
    "Now we'll turn to more possible duplicate instances. We suspect the same user has copy-pasted an identical review multiple times when that verbatim review appears for the same condition and (generic) drug name with the same rating. Let's look at all such instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002a65fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.duplicated(subset=['genericName', 'condition', 'review', 'rating'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c52785",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated(subset=['genericName', 'condition', 'review', 'rating'])] \\\n",
    "[['genericName', 'condition', 'review', 'rating', 'date']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc90eda",
   "metadata": {},
   "source": [
    "The review texts all appear to be unique. As long as the review and its duplicate appear close in time to one another (within days), then these should be collapsed into a single review with the respective useful counts added together.\n",
    "\n",
    "First we'll check on the dates. The following cell will show the respective dates of when these duplicated reviews appeared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5700f3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in df[df.duplicated(subset=['genericName', 'condition', 'review', 'rating'])].index:\n",
    "    two_indices = list(df[df.review == df.loc[ind].review].index)\n",
    "    print(df.loc[two_indices[0]].date, '... and ...', df.loc[two_indices[1]].date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ad7ce7",
   "metadata": {},
   "source": [
    "They're all identical dates except one that is a day apart.\n",
    "\n",
    "We'll collapse these into single records and add the useful counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ab791f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ind in df[df.duplicated(subset=['genericName', 'condition', 'review', 'rating'])].index:\n",
    "    two_indices = list(df[df.review == df.loc[ind].review].index)\n",
    "    x, y = two_indices[0], two_indices[1]\n",
    "    count = int(df.loc[x].usefulCount + df.loc[y].usefulCount)\n",
    "    df.at[x, 'usefulCount'] = count\n",
    "    df.drop([y], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb75e363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT re-run this cell out of sequence\n",
    "# to use the dataframe as it was at this stage, un-comment, run, and re-comment the cell that follows after it.\n",
    "df_bookmark_3 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dad01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df_bookmark_3.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516cf66c",
   "metadata": {},
   "source": [
    "## Identifying birth control type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03a035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "birth_control_dict = {\n",
    "    'IUD': ['Skyla', 'Mirena', 'Kyleena', 'Liletta', 'ParaGard'],\n",
    "    'patch': ['Ortho Evra', 'Xulane'],\n",
    "    'implantable': ['Implanon', 'Nexplanon'],\n",
    "    'vaginal': ['NuvaRing'],\n",
    "    'injectable': ['Depo-Provera', 'depo-subQ provera', 'Provera'],\n",
    "    'emergency': ['Plan B', 'ella', 'Fallback Solo', 'Aftera', 'Take Action', 'Next Choice',\n",
    "                       'My Way', 'EContra EZ'],\n",
    "    'pill': ['Yasmin', 'Ortho Tri-Cyclen', 'Alesse', 'Aviane', 'Sprintec', 'Tri-Sprintec', 'Mircette',\n",
    "             'Seasonique', 'Yaz', 'Lutera', 'Portia', 'Camila', 'Apri', 'Beyaz', 'Desogen', 'Kariva',\n",
    "             'TriNessa', 'Zarah', 'Estarylla', 'Mononessa', 'Gianvi', 'Jolivette', 'Loestrin', 'Microgestin',\n",
    "             'Ortho-Cyclen', 'Ortho-Novum', 'Necon', 'Femcon', 'Marlissa', 'Aubra', 'Viorele', 'Vestura',\n",
    "             'Norlyda', 'Ortho Cyclen', 'Lybrel', 'Pirmella', 'Larin', 'Tarina', 'Previfem', 'Tri-Estarylla',\n",
    "             'Lessina', 'Elinest', 'Cryselle', 'Ortho-Cept', 'Falmina', 'Altavera', 'Tri-Lo-Marzia', 'Taytulla',\n",
    "             'CamreseLo', 'Philith', 'Dasetta', 'Gildess', 'Ovral', 'Jencycla', 'Tri-Linyah', 'Enskyce',\n",
    "             'Orsythia', 'Sronyx', 'Velivet', 'Reclipsen', 'Nikki', 'Levlen', 'Loryna', 'Juleber', 'Trivora',\n",
    "             'Zenchent', 'Tri-Previfem', 'Lyza', 'Seasonale', 'Mono-Linyah', 'Alyacen', 'Opcicon']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c72c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_fix_1(shortBrandName):\n",
    "    for method in birth_control_dict:\n",
    "        if shortBrandName in birth_control_dict[method]:\n",
    "            return method\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df['method'] = df.shortBrandName.apply(lambda x: None if x == None else method_fix_1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f016e022",
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_dict = {\n",
    "    'patch': ['Ethinyl estradiol / norelgestromin'],\n",
    "    'IUD': ['Copper'],\n",
    "    'implantable': ['Etonogestrel'],\n",
    "    'emergency': ['Ulipristal'],\n",
    "    'vaginal': ['Ethinyl estradiol / etonogestrel'],\n",
    "    'pill': ['Ethinyl estradiol / levonorgestrel',\n",
    "             'Drospirenone / ethinyl estradiol / levomefolate calcium',  'Mestranol / norethindrone',\n",
    "             'Ethinyl estradiol / norgestimate', 'Ethinyl estradiol / norethindrone',\n",
    "             'Norethindrone', 'Drospirenone / ethinyl estradiol', 'Desogestrel / ethinyl estradiol',\n",
    "             'Ethinyl estradiol / norgestrel', 'Ethinyl estradiol / folic acid / levonorgestrel',\n",
    "             'Ethinyl estradiol / ethynodiol', 'Dienogest / estradiol'],\n",
    "    'injectable': ['Medroxyprogesterone']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451afe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_fix_2(generic):\n",
    "    for method in generic_dict:\n",
    "        if generic in generic_dict[method]:\n",
    "            return method\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df['method'] = df.apply(lambda x: method_fix_2(x.genericName) if x.method == None else x.method, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8e9683",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\n",
    "    (df.method.isna())\n",
    "].genericName.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf82be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in df[df.genericName == 'Nonoxynol 9'].index:\n",
    "    show_review(ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2f391c",
   "metadata": {},
   "source": [
    "We could create a spermicide label, but there would only be two records for it, so we'll just drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9928a2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([172606, 209857], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f957db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in df[\n",
    "    (df.genericName == 'Levonorgestrel') &\n",
    "    (df.method.isna())\n",
    "].index[:10]:\n",
    "    show_review(ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a94bb4e",
   "metadata": {},
   "source": [
    "All of these examples describe emergency contraception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5934df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_dict['emergency'].append('Levonorgestrel')\n",
    "df['method'] = df.apply(lambda x: method_fix_2(x.genericName) if x.method == None else x.method, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d2fe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\n",
    "    (df.method.isna())\n",
    "].genericName.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52a0cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT re-run this cell out of sequence\n",
    "# to use the dataframe as it was at this stage, un-comment, run, and re-comment the cell that follows after it.\n",
    "df_bookmark_4 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bc2d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df_bookmark_4.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c17281a",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd35a019",
   "metadata": {},
   "source": [
    "Relevant columns now are:\n",
    "- condition (emergency v birth control, although this is flawed)\n",
    "- rating\n",
    "- date\n",
    "- usefulCount\n",
    "- shortBrandName\n",
    "- method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75172cf",
   "metadata": {},
   "source": [
    "## Data over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c118f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average rating for each method\n",
    "average_ratings = df.groupby('method')['rating'].mean().reset_index()\n",
    "\n",
    "# Create a bar chart using Seaborn\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Set the font scale to increase text size\n",
    "sns.set(font_scale=1.5)\n",
    "sns.barplot(\n",
    "    x='method',\n",
    "    y='rating',\n",
    "    data=average_ratings,\n",
    "    order=average_ratings.sort_values('rating', ascending=False)['method'],\n",
    "    palette='deep'\n",
    ")\n",
    "plt.xlabel('Method')\n",
    "plt.ylabel('Average Rating')\n",
    "plt.title('Average Rating for Each Method')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d67bcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year from datetime\n",
    "df['year'] = df['datetime'].dt.year\n",
    "\n",
    "# Group by 'year' and 'method', calculate the average rating for each group\n",
    "average_ratings = df.groupby(['year', 'method'])['rating'].mean().reset_index()\n",
    "\n",
    "# Pivot the DataFrame to have 'method' as columns and 'year' as index\n",
    "pivot_table = average_ratings.pivot_table(index='year', columns='method', values='rating')\n",
    "\n",
    "# Plot the data\n",
    "pivot_table.plot(kind='line', marker='o', figsize=(14, 6))\n",
    "plt.title('Average Rating of Each Method by Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Average Rating')\n",
    "plt.legend(title='Method', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb99ad4",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- Ratings generally declined after the number of ratings increased significantly in 2015.\n",
    "- Emergency contraception has largely been more popular than other methods.\n",
    "- IUDs, patches, and vaginal contraceptives tend to be more popular than pills and implantables.\n",
    "- Injectable methods are consistently the least popular."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428ccafa",
   "metadata": {},
   "source": [
    "## Rating and upvotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45842320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate total counts for each rating\n",
    "# rating_counts = df['rating'].value_counts().reset_index().rename(columns={'index': 'rating', 'rating': 'count'})\n",
    "\n",
    "# # Create a bar chart using Seaborn\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.barplot(x='rating', y='count', data=rating_counts, palette='muted')\n",
    "# plt.xlabel('Rating')\n",
    "# plt.ylabel('Total Counts')\n",
    "# plt.title('Total Counts for Each Rating')\n",
    "# plt.show()\n",
    "\n",
    "# Count the occurrences of each rating\n",
    "rating_counts = df['rating'].value_counts()\n",
    "\n",
    "# Sort the index for better visualization\n",
    "rating_counts = rating_counts.sort_index()\n",
    "\n",
    "# Plotting the bar graph\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.bar(rating_counts.index, rating_counts.values, color='skyblue')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2856b528",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- There tend to be more positive ratings.\n",
    "- Negative ratings are concentrated on the worst rating (1.0).\n",
    "- There is a slight peak at 5.0. This indicates an attempt at neutrality.\n",
    "\n",
    "In light of this distribution, we could recommend a 3-, 4-, or 5-point rating system that might be a better fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b378fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average usefulCount for each rating\n",
    "average_useful_count = df.groupby('rating')['usefulCount'].mean().reset_index()\n",
    "\n",
    "# Create a bar chart using Seaborn\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.barplot(x='rating', y='usefulCount', data=average_useful_count, palette='viridis')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Average Useful Count')\n",
    "plt.title('Average Useful Count for Each Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56df8d5",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- There is no real gain in usefulness other than for ratings 8 and above, which we saw earlier are also more prevalent than all other ratings except for 1.0, the lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f598f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average usefulCount for each rating\n",
    "average_useful_count = df[df.usefulCount > df.usefulCount.quantile(.80)].groupby('rating')['usefulCount'].mean().reset_index()\n",
    "\n",
    "# Create a bar chart using Seaborn\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.barplot(x='rating', y='usefulCount', data=average_useful_count, palette='viridis')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Average Useful Count')\n",
    "plt.title('Average Useful Count for Each Rating — Top 20% of Useful Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3564579",
   "metadata": {},
   "source": [
    "There's a relative spike among ratings of 3.0. Let's look at some highly upvoted reviews with a rating of 3.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1c5405",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in df[df.rating == 3].sort_values(by='usefulCount', ascending=False).index[:10]:\n",
    "    show_review(ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94509a45",
   "metadata": {},
   "source": [
    "Nothing jumps out about these reviews except that they are certainly negative and could all probably have been 1.0 ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6c695c",
   "metadata": {},
   "source": [
    "## Term frequency analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b085f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the standard list of stopwords\n",
    "nltk.download('stopwords', quiet=True)\n",
    "# start our own list of stopwords with these words\n",
    "stop_list = stopwords.words('english')\n",
    "\n",
    "# consider trimming the stop_list to keep the following for the purposes of certain n-grams:\n",
    "# 44-59 be/have/do verbs\n",
    "# 64-178 prepositions/subordinate conjunctions/modals\n",
    "\n",
    "# add punctuation characters\n",
    "for char in string.punctuation:\n",
    "    stop_list.append(char)\n",
    "# add empty string\n",
    "stop_list.extend(['', 'ha', 'wa', '``', \"''\"])\n",
    "# PUT THIS SOMEWHERE ELSE\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f230caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews, corpus, tokens = {}, {}, {}\n",
    "\n",
    "reviews['vaginal'] = df[df.method == 'vaginal'].review_lower.tolist() # a list of reviews\n",
    "\n",
    "corpus['vaginal'] = ' '.join(reviews['vaginal'])\n",
    "\n",
    "tokens['vaginal'] = nltk.word_tokenize(corpus['vaginal'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c627807",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews, corpus, tokens, tokens_joined = {}, {}, {}, {}\n",
    "\n",
    "for method_ in df.method.unique():\n",
    "    reviews[method_] = df[df.method == method_].review_lower.tolist() # a list of all reviews of one method\n",
    "    corpus[method_] = ' '.join(reviews[method_]) # the above as a single string with spaces\n",
    "    tokens[method_] = nltk.word_tokenize(corpus[method_]) # the above as a list of words\n",
    "    tokens_joined[method_] = ' '.join(tokens[method_]) # the above as a single string with spaces\n",
    "\n",
    "tokens_joined_list = [tokens_joined[method_] for method_ in df.method.unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90681d30",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2), stop_words=stop_list)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(tokens_joined_list)\n",
    "\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f\"Important words in Document {i+1}:\")\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "    feature_index = tfidf_matrix[i, :].nonzero()[1]\n",
    "    tfidf_scores = zip(feature_index, [tfidf_matrix[i, x] for x in feature_index])\n",
    "    top_words = sorted(tfidf_scores, key=lambda x: x[1], reverse=True)[:25]  # Adjust 5 to desired number of top words\n",
    "    for word_index, score in top_words:\n",
    "        print(f\"{feature_names[word_index]} (TF-IDF Score: {score:.2f})\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65899bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that takes a list of documents and 1) tokenizes them, 2) lemmatizes them, and 3) removes stopwords\n",
    "\n",
    "# for example, to execute this function use make_tokens(df.review.tolist())\n",
    "\n",
    "# IN: a list of documents\n",
    "# OUT: a list of tokens\n",
    "\n",
    "def make_tokens(docs_list, stop_list=stop_list):\n",
    "    # join documents into a single string\n",
    "    docs_joined = ' '.join(docs_list)\n",
    "    # tokenize the single string into a list of tokens\n",
    "    tokens = nltk.word_tokenize(docs_joined)\n",
    "    # lemmatize the list of tokens\n",
    "    tokens_lemmatized = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    # stop the list of tokens\n",
    "    tokens_stopped = [word for word in tokens_lemmatized if \\\n",
    "                      word not in stop_list]\n",
    "    return tokens_stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfca77c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that generates a word cloud of a given list of words\n",
    "def make_wordcloud(wordlist, colormap='Greens', title=None):\n",
    "    # instantiate wordcloud\n",
    "    wordcloud = WordCloud(\n",
    "        width=600,\n",
    "        height=400,\n",
    "        colormap=colormap,\n",
    "        collocations = True\n",
    "    )\n",
    "    return wordcloud.generate(','.join(wordlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9f3a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that plots the word cloud\n",
    "def plot_wordcloud(wordcloud):\n",
    "    # plot wordcloud\n",
    "    plt.figure(figsize = (12, 15)) \n",
    "    plt.imshow(wordcloud) \n",
    "    plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fb4dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_lower'] = df['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29556b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_summary(method_):\n",
    "    tokens = make_tokens(df[df.method == method_].review_lower.tolist())\n",
    "    plot_wordcloud(make_wordcloud(tokens))\n",
    "    print(FreqDist(tokens).most_common(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92995370",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_summary('injectable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df59a289",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_tokens = []\n",
    "\n",
    "for method_ in df.method.unique():\n",
    "    reviews = df[df.method == method_].review_lower.tolist() # a list of documents\n",
    "    method_tokens.append(make_tokens(df[df.method == method_].review_lower.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd57d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_tfidf_top_features(documents,n_top=10):\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,  stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(method_tokens)\n",
    "#     importance = np.argsort(np.asarray(tfidf.sum(axis=0)).ravel())[::-1]\n",
    "#     tfidf_feature_names = np.array(tfidf_vectorizer.get_feature_names())\n",
    "#     return tfidf_feature_names[importance[:n_top]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f099ff8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tfidf_top_features(method_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f323d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(method_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52a76ea",
   "metadata": {},
   "source": [
    "What is good or bad about each method\n",
    "\n",
    "What makes good (or bad) reviews useful about each method\n",
    "\n",
    "For each birth control method, make a function that summarizes what people are saying good and bad about it.\n",
    "\n",
    "Create a weighted rating (rating times usefulCount) and use this to inform topic modeling.\n",
    "\n",
    "explore each feature vs. rating and each feature vs. useful\n",
    "\n",
    "explore topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e2a3fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ind in df[df.method == 'implantable'].sort_values(by='usefulCount', ascending=False)[:10].index:\n",
    "    show_review(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99951e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.method.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d9dc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "pill_tokens = make_tokens(df[df.method == 'pill'].review_lower.tolist(), stop_list=stop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee0f62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "implantable_tokens = make_tokens(df[df.method == 'implantable'].review_lower.tolist(), stop_list=stop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa20bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(make_wordcloud(pill_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3132add",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(make_wordcloud(implantable_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcfa15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('method').genericName.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cee5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('method').shortBrandName.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780543e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('method').rating.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249ec7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('method').usefulCount.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ec09a2",
   "metadata": {},
   "source": [
    "This shows the average useful count by rating from 1 to 10. It seems that ratings of 8 and above are considered more useful than the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935bf064",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 20\n",
    "\n",
    "uv = list(df.usefulCount.values)\n",
    "uv.sort(reverse=True)\n",
    "n = 0\n",
    "while sum(uv[:n]) < threshold / 100 * df.usefulCount.sum():\n",
    "    n += 1\n",
    "print(str(int(n * 100 / len(df)))+'%','of the reviews received', str(threshold)+'%', 'of all the upvotes.')\n",
    "print('This includes reviews with', uv[n], 'or more upvotes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7a197b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.usefulCount >= 41].rating.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0584d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 40\n",
    "\n",
    "uv = list(df.usefulCount.values)\n",
    "uv.sort(reverse=True)\n",
    "n = 0\n",
    "while sum(uv[:n]) < threshold / 100 * df.usefulCount.sum():\n",
    "    n += 1\n",
    "print(str(int(n * 100 / len(df)))+'%','of the reviews received', str(threshold)+'%', 'of all the upvotes.')\n",
    "print('This includes reviews with', uv[n], 'or more upvotes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ef6b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.usefulCount >= 20].rating.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eff98ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 60\n",
    "\n",
    "uv = list(df.usefulCount.values)\n",
    "uv.sort(reverse=True)\n",
    "n = 0\n",
    "while sum(uv[:n]) < threshold / 100 * df.usefulCount.sum():\n",
    "    n += 1\n",
    "print(str(int(n * 100 / len(df)))+'%','of the reviews received', str(threshold)+'%', 'of all the upvotes.')\n",
    "print('This includes reviews with', uv[n], 'or more upvotes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf368829",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.usefulCount >= 11].rating.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59201952",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 80\n",
    "\n",
    "uv = list(df.usefulCount.values)\n",
    "uv.sort(reverse=True)\n",
    "n = 0\n",
    "while sum(uv[:n]) < threshold / 100 * df.usefulCount.sum():\n",
    "    n += 1\n",
    "print(str(int(n * 100 / len(df)))+'%','of the reviews received', str(threshold)+'%', 'of all the upvotes.')\n",
    "print('This includes reviews with', uv[n], 'or more upvotes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f85fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.usefulCount >= 6].rating.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eebd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 95\n",
    "\n",
    "uv = list(df.usefulCount.values)\n",
    "uv.sort(reverse=True)\n",
    "n = 0\n",
    "while sum(uv[:n]) < threshold / 100 * df.usefulCount.sum():\n",
    "    n += 1\n",
    "print(str(int(n * 100 / len(df)))+'%','of the reviews received', str(threshold)+'%', 'of all the upvotes.')\n",
    "print('This includes reviews with', uv[n], 'or more upvotes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1b5e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.usefulCount >= 3].rating.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66428a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = range(0,len(df),100)\n",
    "Y = []\n",
    "for x in X:\n",
    "    Y.append(sum(uv[:x]))\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(X,Y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813e1d2e",
   "metadata": {},
   "source": [
    "This shows the cumulative sum of upvotes. For example, if we go 5% of the reviews in from the left on the x-axis, we would reach up to 33% of the total upvotes on the y-axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45747da3",
   "metadata": {},
   "source": [
    "# feature engineering ideas\n",
    "\n",
    "- word count\n",
    "- character count\n",
    "- words in all caps\n",
    "- average word length\n",
    "- whether words are in English (spelled correctly)\n",
    "- whether it includes characters such as exclamation points, question marks, (especially repeatedly), and emoticons\n",
    "- whether it mentions the brand or generic name in the review\n",
    "- whether it uses slang versus technical language\n",
    "- whether it mentions touchy subjects such as abortion\n",
    "- ngrams\n",
    "- does it mention switching treatments, comparison to other methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5e1743",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea7fb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['raw_tokens'] = df.review.apply(lambda x: nltk.word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9098cf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_lower'] = df['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d900f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_useful(feature, low=0.15, high=0.85):\n",
    "    X = range(int(df[feature].quantile(low)), int(df[feature].quantile(high)))\n",
    "    Y = []\n",
    "    for x in X:\n",
    "        Y.append(df[df[feature] == x].usefulCount.mean())\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(X,Y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bee287",
   "metadata": {},
   "source": [
    "# all caps words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03586b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_caps_fix(tokens_list):\n",
    "    count = 0\n",
    "    for token in tokens_list:\n",
    "        if len(token) > 2 and token.isupper():\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "df['all_caps'] = df.raw_tokens.apply(lambda x: all_caps_fix(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd565b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.all_caps.value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf64364",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_useful('all_caps', high=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98265ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_features.append('all_caps')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3a5bf1",
   "metadata": {},
   "source": [
    "# no caps usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab215df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['no_caps'] = df.apply(lambda x: 1 if x.review == x.review_lower else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbf09eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.no_caps.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66389af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.no_caps == 1].usefulCount.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0834fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.no_caps == 0].usefulCount.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ce6323",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_features.append('no_caps')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ae7273",
   "metadata": {},
   "source": [
    "# exclaim count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63383822",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['exclaim_count'] = df.raw_tokens.apply(lambda x: x.count('!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daa35e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.exclaim_count.value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9329eeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_useful('exclaim_count', high=0.995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d94e763",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_features.append('exclaim_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ac7139",
   "metadata": {},
   "source": [
    "# question count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77feeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['question_count'] = df.raw_tokens.apply(lambda x: x.count('?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c66ed31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.question_count.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ded6024",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_useful('question_count', low=0.01, high=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dab3917",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_features.append('question_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7d0c69",
   "metadata": {},
   "source": [
    "# word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96885cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'] = df.raw_tokens.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eca5afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_useful('word_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a28e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_features.append('word_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed77a716",
   "metadata": {},
   "source": [
    "# character count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19971da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['character_count'] = df.review.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f588926",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_useful('character_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2b34da",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_features.append('character_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072b7f77",
   "metadata": {},
   "source": [
    "# characters per word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ff52c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cpw'] = 100 * df.character_count / df.word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f8c09b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.cpw.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb6cc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_useful('cpw', low=0.01, high=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6175f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_features.append('cpw')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2ea778",
   "metadata": {},
   "source": [
    "# age disclosure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee343f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_disclosure_feature(review):\n",
    "    if re.search('[1-4][0-9] +y(ea)?rs? +(old|of age)', review) or \\\n",
    "    re.search('(pregnant( +at)?|age( +of)?|being) +[1-4][0-9]', review) or \\\n",
    "    re.search('(teen|ty|one|two|three|four|five|six|seven|eight|nine) +y(ea)?rs? +(old|of +age)', review) or \\\n",
    "    re.search('i +(am +|was +|will +be +|would have been +)(not even +)?(now +)?(only +)?(just +)?(maybe +)?[1-4][0-9](\\s|\\.|\\!|\\?)', review):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "df['age_disclosure'] = df.review_lower.apply(lambda x: 1 if age_disclosure_feature(x) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd30393",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.age_disclosure.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b261f5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.age_disclosure == 1].usefulCount.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7828d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.age_disclosure == 0].usefulCount.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb544667",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_features.append('age_disclosure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b24455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT re-run this cell out of sequence\n",
    "# to use the dataframe as it was at this stage, un-comment, run, and re-comment the cell that follows after it.\n",
    "df_bookmark_5 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b48678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df_bookmark_5.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152b9411",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4debd69",
   "metadata": {},
   "source": [
    "# separate pos / neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c4c6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neg = df[df.rating < 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5a66c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0093151",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_reviews = df_neg.review.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad4d1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "neg_tokens = make_tokens(neg_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5be0881",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = [\"me\", 'you', 'th\"ey', 'we', \"we\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7e001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "barf = ['\"', \"I've\", 'tried', 'a', 'few']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9931c2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_wordcloud(wordlist, colormap='Greens', title=None):\n",
    "    # instantiate wordcloud\n",
    "    wordcloud = WordCloud(\n",
    "        width=600,\n",
    "        height=400,\n",
    "        colormap=colormap,\n",
    "        collocations = True\n",
    "    )\n",
    "    return wordcloud.generate(','.join(wordlist))\n",
    "\n",
    "def plot_wordcloud(wordcloud):\n",
    "    # plot wordcloud\n",
    "    plt.figure(figsize = (12, 15)) \n",
    "    plt.imshow(wordcloud) \n",
    "    plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f964ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(make_wordcloud(ff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4654df1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "uv = list(df_neg.usefulCount.values)\n",
    "uv.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b6c93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = range(0,len(df_neg),50)\n",
    "Y = []\n",
    "for x in X:\n",
    "    Y.append(sum(uv[:x]))\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(X,Y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4d1091",
   "metadata": {},
   "source": [
    "## Results function\n",
    "\n",
    "We'll create a function that takes the pipeline we've created and displays only the results we're interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08889669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_results(pipeline):\n",
    "    # fit the pipeline to the training data\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    # generate predictions for the test data\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    # display the training and test accuracy scores\n",
    "    print(f\"Training Score: {round(pipeline.score(X_train, y_train),4)} \\\n",
    "    \\nTest Score:     {round(pipeline.score(X_test, y_test),4)}\")\n",
    "    \n",
    "    # plot the normalized confusion matrix\n",
    "    plot_confusion_matrix(estimator=pipeline, X=X_test, y_true=y_test, cmap='Greens', \n",
    "                          normalize='true', \n",
    "                          display_labels=['Non-positive', 'Positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac5b238",
   "metadata": {},
   "source": [
    "# save and reload preprocessed set\n",
    "\n",
    "At this stage we will save and reload the preprocessed set in order to avoid taking the time to repeat earlier work everytime we open the notebook.\n",
    "\n",
    "The saved version has restored or deleted all records with missing condition labels.\n",
    "\n",
    "We have established pairs in the list `twins` but we have NOT yet deleted either member of any pair or dealt with the confusion between brand and generic drug names.\n",
    "\n",
    "The size of the dateframe is nearly the same as its original version, roughly 215,000 records.\n",
    "\n",
    "In the future, store the functions with this?\n",
    "\n",
    "Store the engineered features list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be815ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = Path('../data/preprocessed.csv')\n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891494f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store engineered_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8bf157",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/preprocessed.csv')\n",
    "df.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25f5f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r engineered_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c08ac9",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "I'll carefully put the pieces together one cell at a time. If it all works, I can combine them later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead89e66",
   "metadata": {},
   "source": [
    "* define target feature using thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f271b6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_threshold = [1, 12]\n",
    "\n",
    "print(len(df[df.usefulCount <= useful_threshold[0]]), len(df[df.usefulCount >= useful_threshold[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e4e4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[\n",
    "    (df.usefulCount > useful_threshold[0]) & \\\n",
    "    (df.usefulCount < useful_threshold[1])\n",
    "].index, inplace=True)\n",
    "\n",
    "df['target'] = df.usefulCount.apply(lambda x: 1 if x >= useful_threshold[1] else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c068c7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(df[['review'] + engineered_features], df['target'], test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1589563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this value to compare to future model crossval scores\n",
    "plurality_cv = round(y_train.value_counts(normalize=True)[1],4)\n",
    "# show the sentiment breakdown\n",
    "round(y_train.value_counts(normalize=True),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ce1a45",
   "metadata": {},
   "source": [
    "----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0ccfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset variables\n",
    "\n",
    "text_preprocessor = None\n",
    "numerical_preprocessor = None\n",
    "preprocessor = None\n",
    "pipeline = None\n",
    "accuracy = None\n",
    "feature_names = None\n",
    "coefficients = None\n",
    "decision_function_values = None\n",
    "importance_df = None\n",
    "feature_importance = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13544530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the standard list of stopwords\n",
    "nltk.download('stopwords', quiet=True)\n",
    "# start our own list of stopwords with these words\n",
    "stop_list = stopwords.words('english')\n",
    "# add punctuation characters\n",
    "# for char in string.punctuation:\n",
    "#     stop_list.append(char)\n",
    "# add empty string\n",
    "# stop_list.extend([''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7186b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop words to keep\n",
    "# 44-59 be/have/do verbs\n",
    "# 64-178 prepositions/subordinate conjunctions/modals\n",
    "stop_list = stop_list[:44] + stop_list[60:64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda9c08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables of interest\n",
    "\n",
    "max_features = None\n",
    "stop_words = stop_list\n",
    "ngram_range = (2,4)\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "# model = SVC(kernel='linear')\n",
    "# model = MultinomialNB() # does not work\n",
    "# model = GaussianNB() # does not work\n",
    "# model = DecisionTreeClassifier(random_state=SEED)\n",
    "# model = BaggingClassifier()\n",
    "# model = RandomForestClassifier(random_state=SEED)\n",
    "# model = AdaBoostClassifier(random_state=SEED)\n",
    "# model = GradientBoostingClassifier(random_state=SEED)\n",
    "# model = XGBClassifier(random_state=SEED)\n",
    "n_features = 25\n",
    "title = '_____ Model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59262f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_preprocessor = TfidfVectorizer(\n",
    "    max_features=max_features,\n",
    "    stop_words=stop_words,\n",
    "    ngram_range=ngram_range\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c874b4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_preprocessor = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3babeb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', text_preprocessor, 'review'),\n",
    "        ('numerical', numerical_preprocessor, engineered_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb952f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a3aad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pipeline.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd86338",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5785e081",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a1c7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = preprocessor.named_transformers_['text'].get_feature_names_out().tolist() + engineered_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5958af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the success of this code seems to depend on whether we feed it a dense or sparse matrix\n",
    "# supposedly the .ravel() method will handle either\n",
    "\n",
    "# this works for SVC, LogisticRegression\n",
    "\n",
    "# --------------------------------------------------------\n",
    "if hasattr(model, 'feature_importances_'):\n",
    "    coefficients = model.feature_importances_\n",
    "elif hasattr(model.coef_, 'toarray'):\n",
    "    coefficients = model.coef_.toarray().flatten()\n",
    "else:\n",
    "    coefficients = model.coef_.flatten()\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# this works for DecisionTreeClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "# seems meaningless in the case of AdaBoost\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# coefficients = model.feature_importances_\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# this works for BaggingClassifier\n",
    "# (but it might not mean anything?)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# coefficients = np.mean([\n",
    "#     tree.feature_importances_ for tree in model.estimators_\n",
    "# ], axis=0)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# coefficients = model.coef_.toarray().flatten()  # Assuming sparse matrix\n",
    "\n",
    "# coefficients = model.coef_.flatten()  # Assuming dense matrix\n",
    "\n",
    "# coefficients = model.coef_.ravel()  # should work for dense or sparse matrix\n",
    "\n",
    "# try:\n",
    "#     # Try to access coef_ (only available for linear kernels)\n",
    "#     coefficients = model.coef_.flatten()\n",
    "# except AttributeError:\n",
    "#     # Handle the case for non-linear kernels\n",
    "#     decision_function_values = pipeline.decision_function(X_train)\n",
    "#     coefficients = (preprocessor.transform(X_train).T @ decision_function_values * y_train).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8043884",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df = pd.DataFrame(feature_names, columns=['Word'])\n",
    "importance_df['Importance'] = np.e**(abs(coefficients))\n",
    "importance_df['Coefficient'] = coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4685ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = importance_df.sort_values(\n",
    "    by = [\"Importance\"], ascending=False\n",
    ").head(n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd135336",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,10), ncols=2)\n",
    "ax[0].set_title(f'Coefficients for {title}')\n",
    "ax[0].set_ylabel('Word')\n",
    "ax[0].set_xlabel('Coefficient')\n",
    "sns.barplot(x='Coefficient', y='Word', data=feature_importance, \n",
    "            palette='coolwarm', ax=ax[0])\n",
    "#plotting feature importances\n",
    "ax[1].set_title(f'Feature Importances for {title}')\n",
    "ax[1].set_ylabel('Word')\n",
    "ax[1].set_xlabel('Importance')\n",
    "sns.barplot(x='Importance', y='Word', data=feature_importance, \n",
    "            palette='coolwarm', ax=ax[1])\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe134d7",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb29ded",
   "metadata": {},
   "source": [
    "# Recommendations\n",
    "\n",
    "Don't know where else to put this right now. At least one review, 27228, is glowingly positive but gave a 1.0 rating, clearly misunderstanding the rating system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66385eca",
   "metadata": {},
   "source": [
    "## Use a different rating system\n",
    "\n",
    "No more than 5 points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2021dcc4",
   "metadata": {},
   "source": [
    "# Further Inquiry"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
