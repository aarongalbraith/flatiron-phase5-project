{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66fc9981",
   "metadata": {},
   "source": [
    "https://archive.ics.uci.edu/dataset/462/drug+review+dataset+drugs+com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace56558",
   "metadata": {},
   "source": [
    "# Flatiron Phase 5 Project\n",
    "\n",
    "## Aaron Galbraith\n",
    "\n",
    "https://www.linkedin.com/in/aarongalbraith \\\n",
    "https://github.com/aarongalbraith\n",
    "\n",
    "### Submitted: November 21, 2023\n",
    "\n",
    "## working contents\n",
    "\n",
    "- **[functions](#functions)<br>**\n",
    "- **[rough overview](#rough-overview)<br>**\n",
    "- **[missing values](#missing-values)<br>**\n",
    "- **[duplicates](#duplicates)<br>**\n",
    "- **[brand / generic pairs](#brand-/-generic-pairs)<br>**\n",
    "- **[further exploration of duplicates (skip for now)](#further-exploration-of-duplicates-(skip-for-now))<br>**\n",
    "- **[contractions](#contractions)<br>**\n",
    "- **[dates](#dates)<br>**\n",
    "- **[ratings](#ratings)<br>**\n",
    "- **[focusing on birth control](#focusing-on-birth-control)<br>**\n",
    "- **[save and reload preprocessed set](#save-and-reload-preprocessed-set)<br>**\n",
    "- **[feature engineering ideas](#feature-engineering-ideas)<br>**\n",
    "- **[rudimentary word cloud maker](#rudimentary-word-cloud-maker)<br>**\n",
    "- **[end](#end)<br>**\n",
    "\n",
    "\n",
    "## Contents\n",
    "\n",
    "- **[Business Understanding](#Business-Understanding)<br>**\n",
    "- **[Data Understanding](#Data-Understanding)**<br>\n",
    "- **[Data Preparation](#Data-Preparation)**<br>\n",
    "- **[Exploration](#Exploration)**<br>\n",
    "- **[Modeling](#Modeling)**<br>\n",
    "- **[Evaluation](#Evaluation)**<br>\n",
    "- **[Recommendations](#Recommendations)<br>**\n",
    "- **[Further Inquiry](#Further-Inquiry)**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a51a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import html\n",
    "import contractions\n",
    "\n",
    "import re\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, accuracy_score, precision_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "SEED = 1979\n",
    "\n",
    "do_grids = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d47c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.read_csv('../data/drugsComTrain_raw.tsv', delimiter='\\t', encoding='latin-1')\n",
    "d2 = pd.read_csv('../data/drugsComTest_raw.tsv', delimiter='\\t', encoding='latin-1')\n",
    "df = pd.concat([d1,d2]).reset_index().drop(columns=['Unnamed: 0', 'index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7430799d",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8039208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_review(index):\n",
    "    print(df.review.loc[index])\n",
    "    display(df[df.review == df.loc[index].review][['drugName', 'condition', 'rating', 'date', 'usefulCount']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810f5cb1",
   "metadata": {},
   "source": [
    "# rough overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa30efe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c2fb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee31c723",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8a8d65",
   "metadata": {},
   "source": [
    "There are some missing condition labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb3b73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drugName.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23a6917",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drugName.value_counts().quantile(.90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf084c5",
   "metadata": {},
   "source": [
    "There are 3,671 unique drug names, and 10% of the drug names have more than 120 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d10d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0fb2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition.value_counts().quantile(.90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c429fa52",
   "metadata": {},
   "source": [
    "There are 916 unique conditionis, and 10% of the conditions have more than 332 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe426fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131673d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rating.hist(bins=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1816c0",
   "metadata": {},
   "source": [
    "Most of the conditions lie at the extremes, and more of them appear to be at the positive extreme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbddc7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('drugName').condition.nunique().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a0bdec",
   "metadata": {},
   "source": [
    "This means that, for example, 1869 drugs treat 1 condition only, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25afff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('condition').drugName.nunique().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4e06ac",
   "metadata": {},
   "source": [
    "This means that 188 conditions are treatable by two drugs, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce3e8f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "print(df.drugName.value_counts())\n",
    "pd.set_option(\"display.max_rows\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b882e193",
   "metadata": {},
   "source": [
    "A casual overview of the drug names indicates that they all seem valid. Some seem to specify drug combinations and/or dosage amounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a37bce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "print(df.condition.value_counts())\n",
    "pd.set_option(\"display.max_rows\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d38884",
   "metadata": {},
   "source": [
    "Oddly, the condition labels often (always?) omit initial 'F' and terminal 'r'. We can isolate instances of the former by searching for conditions that start with a lower case letter.\n",
    "\n",
    "We will eventually trim our records to a number of conditions that Planned Parenthood specializes in treating, but we will need all the records to help us determine missing condition labels. After we have restored (or discarded) all missing condition labels, we can drop the conditions outside the scope of this review."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8106ca",
   "metadata": {},
   "source": [
    "## dates\n",
    "\n",
    "(Do this date analysis *after* we have trimmed to just the records we'll use?)\n",
    "\n",
    "There's probably a datetime method for this, but the following will produce month // day // year, and then we can figure out the earliest and latest dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55372655",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = df.date.apply(lambda x: re.split(r'\\W+', x)[0])\n",
    "df['day'] = df.date.apply(lambda x: int(re.split(r'\\W+', x)[1]))\n",
    "df['year'] = df.date.apply(lambda x: int(re.split(r'\\W+', x)[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c121c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.year.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb949790",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.year == 2008].month.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ebef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.year == 2008) &\n",
    "   (df.month == 'February')\n",
    "  ].day.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aab5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.year.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc6484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.year == 2017].month.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9128bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.year == 2017) &\n",
    "   (df.month == 'November')\n",
    "  ].day.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee11e984",
   "metadata": {},
   "source": [
    "The reviews span from February 24, 2008 to November 30, 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bbc328",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.year.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f21b725",
   "metadata": {},
   "source": [
    "## review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b50e58",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(df.review[i], '\\n-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c231a3df",
   "metadata": {},
   "source": [
    "# language cleaning\n",
    "\n",
    "Before we go any further, we would like to clean up some of the review text. In particular, there are many escaped characters, especially apostrophes.\n",
    "\n",
    "Here is an example of a contraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918943ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.review[3][56:69]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01928594",
   "metadata": {},
   "source": [
    "Here is how the html function fixes it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb070d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "html.unescape(df.loc[3][2])[56:64]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db94b9e7",
   "metadata": {},
   "source": [
    "Here is how the contractions function fixes (the html function's fix of) it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fd323e",
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions.fix(html.unescape(df.loc[3][2]))[56:65]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ca4963",
   "metadata": {},
   "source": [
    "Here is an instance of \"ain't\" with the same functions applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96292a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.review.loc[507][75:99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33e2ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "html.unescape(df.review.loc[507])[75:94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f985216",
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions.fix(html.unescape(df.review.loc[507]))[75:96]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cb4805",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.review.str.contains('ain&#039;t')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e39129",
   "metadata": {},
   "source": [
    "There are 53 instances of \"ain't\".\n",
    "\n",
    "I'm currently having difficulty downloading the package that appropriately fixes \"ain't\" into \"is not\" or \"are not\" etc. This shouldn't matter after I remove stop words. I think it will be helpful to exclude negatives like \"no\" and \"not\" from the stop words. It could certainly be of help to look for bigrams like \"not good\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a06deef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.review = df.review.apply(lambda x: contractions.fix(html.unescape(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f739c867",
   "metadata": {},
   "source": [
    "# missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09374cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition.isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dee913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition.fillna('missing', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb42513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123415b0",
   "metadata": {},
   "source": [
    "We noticed another condition label that was meant to indicate missing and should be accordingly changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba096b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition = df.condition.apply(lambda x: 'missing' if 'Not Listed' in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87a2b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340daccb",
   "metadata": {},
   "source": [
    "We've identified some actual missing condition labels, but we noticed there are more condition labels that seem suspicious, particularly ones that start with something other than an upper case character. Let's look at all such condition labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51f8475",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df[(~df.condition.str[0].isin(list(string.ascii_uppercase))) &\n",
    "   (df.condition != 'missing')\n",
    "  ].condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0203557",
   "metadata": {},
   "source": [
    "These fall into three categories. Ones that include \"users found this comment helpful\" should be regarded as erroneous and therefore missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7938f498",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition = df.condition.apply(lambda x: 'missing' if 'users found' in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328dccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040362b4",
   "metadata": {},
   "source": [
    "Ones that show a clipped copy of the drug name label and end with a parenthesis should also be regarded as missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1786a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition = df.condition.apply(lambda x: 'missing' \\\n",
    "                                  if x[0] not in list(string.ascii_uppercase) and \\\n",
    "                                  x[-1] in ['(', ')'] \\\n",
    "                                  else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd34394",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db23dd5",
   "metadata": {},
   "source": [
    "# restoring erroneous condition labels\n",
    "\n",
    "(skip this step because we're just focusing on birth control?)\n",
    "\n",
    "Most of the ones that show a clipped version of the condition label can possibly be restored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf446b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition_restore(condition):\n",
    "    if condition.split()[-1] in ['Disorde', 'eve', 'Shoulde', 'Cance']:\n",
    "        condition = condition+'r'\n",
    "    if condition.split()[0] in ['acial', 'ibrocystic', 'ungal', 'amilial', 'ailure', 'ever', \\\n",
    "                                'emale', 'unctional', 'actor', 'ibromyalgia', 'atigue']:\n",
    "        condition = 'F'+condition\n",
    "    if condition.split()[0] in ['llicular', 'llicle', 'lic', 'cal']:\n",
    "        condition = 'Fo'+condition\n",
    "    if condition.split()[0] in ['mance']:\n",
    "        condition = 'Perfor'+condition\n",
    "    if condition.split()[0] in ['zen']:\n",
    "        condition = 'Fro'+condition\n",
    "    if condition.split()[0] in ['mis']:\n",
    "        condition = 'Dermatitis Herpetifor'+condition\n",
    "    return condition\n",
    "\n",
    "df.condition = df.condition.apply(lambda x: condition_restore(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727b8ece",
   "metadata": {},
   "source": [
    "Let's look at what we have left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d86806",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df[(~df.condition.str[0].isin(list(string.ascii_uppercase))) &\n",
    "   (df.condition != 'missing')\n",
    "  ].condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4e0d6a",
   "metadata": {},
   "source": [
    "\"von Willebrand's Disease\" appears to be a naturally uncapitalized condition. The others have been impossible to restore and will also be regarded as missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8196709",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition = df.condition.apply(lambda x: 'missing' \\\n",
    "                                  if x[0] not in list(string.ascii_uppercase) and \\\n",
    "                                  x.split()[0] != 'von' \\\n",
    "                                  else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37732b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f6929c",
   "metadata": {},
   "source": [
    "We will be able to restore more of these missing condition labels after we do some work with duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9871364d",
   "metadata": {},
   "source": [
    "# duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393fcf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb479d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeb3cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_review(178703)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6343452c",
   "metadata": {},
   "source": [
    "This is curious. The same review is recorded four times. There are two identical pairs, where the difference between the pairs is the drug name. We can drop one from each pair, but the pairs themselves will need to be revisited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491172b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92393be0",
   "metadata": {},
   "source": [
    "# brand / generic pairs\n",
    "\n",
    "The main type of duplicate we should look out for is records with duplicate reviews, as those likely indicate some kind of actual erroneous duplication. Let's see how many of those there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c502008",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated(subset=['review']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6350453c",
   "metadata": {},
   "source": [
    "That's a lot!\n",
    "\n",
    "Let's explore some facets of these duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334b676a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.duplicated(subset=df.columns.difference(['drugName']))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a80d99e",
   "metadata": {},
   "source": [
    "The vast majority of duplicate reviews are accounted for by different drug names. Let's explore some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60005a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated(subset=df.columns.difference(['drugName']))].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087304b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_review(524)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bbc6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_review(574)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a3279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_review(726)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d582c56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_review(1070)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d6925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_review(1375)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d32f5a6",
   "metadata": {},
   "source": [
    "These five examples make clear that the vast majority of duplicates are due to double-entry; (nearly) every review is entered once with its generic name and once with its brand name.\n",
    "\n",
    "We can use this phenomenon to restore some of the missing condition labels. If a missing condition label is part of such a unique pair, then we can confidently assign it the condition of its pair-mate.\n",
    "\n",
    "Let's broaden our search to records that duplicate every feature other than drug name and condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3943922",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.duplicated(subset=df.columns.difference(['drugName', 'condition']))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e04bd6",
   "metadata": {},
   "source": [
    "This is how many records are duplicates of other records in all values EXCEPT (POSSIBLY) drug name and condition. If a record is duplicated in this manner, the second (and third, fourth, etc.) instance will be captured in this bucket of dupes.\n",
    "\n",
    "If we check only this bucket for dupes, we can see whether there are any triplets, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853f5f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dupes = df[df.duplicated(subset=df.columns.difference(['drugName', 'condition']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8b80cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_dupes[df_dupes.duplicated(subset=df_dupes.columns.difference(['drugName', 'condition']))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ded3de",
   "metadata": {},
   "source": [
    "There is only one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2294a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dupes[df_dupes.duplicated(subset=df_dupes.columns.difference(['drugName', 'condition']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5d8cdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_review(140144)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82869978",
   "metadata": {},
   "source": [
    "There are 6 records with the same review, date, rating, and condition. (The reviews on October 5, 2012, appear to be just a coincidence of the same review wording.) Because they're on the *same day*, it seems likely that these reviews were possibly entered repeatedly by the same person. The two with a useful count of 10 are likely a brand/generic pair.\n",
    "\n",
    "As for the other 4, it's not clear what is going on. We will (would) later discover that there is also some discrepancy as to which of these is a brand or generic name. Since the review text isn't very descriptive, and the useful count is so low, (and it doesn't pertain to the main conditions treated by Planned Parenthood), let's just drop all 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016fcbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([60998, 119972, 133212, 140144], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a807ed",
   "metadata": {},
   "source": [
    "Now we should be able to create a list of pairs of indices of records that match in all features except possibly drug name and condition. To make this run faster, we'll first create a way to sort them by date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e73f01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ⏰ record the time for this cell -- usually 11-12 s\n",
    "\n",
    "# create stripped down dataframe that does not have drug names or conditions\n",
    "# we don't need these features for this operation because we're checking for matches on all other features\n",
    "df_pairs = df.drop(columns=['drugName', 'condition']).copy()\n",
    "\n",
    "# create a list of indices of records that duplicate everything other than drug name and condition\n",
    "df_dupes = df_pairs[df_pairs.duplicated()].index.tolist().copy()\n",
    "\n",
    "# create and populate a dictionary whose keys are dates and whose values are indices\n",
    "dates_dict = {}\n",
    "# populate dictionary with keys that are dates belonging to the duplicates\n",
    "for date_ in list(set(df[df.index.isin(df_dupes)].date.tolist())):\n",
    "    dates_dict[date_] = []\n",
    "# populate dictionary with values that are indices that are NOT from the duplicate list but DO share that date\n",
    "for i in df[~df.index.isin(df_dupes)].index:\n",
    "    dates_dict[df.loc[i].date].append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881e913d",
   "metadata": {},
   "source": [
    "Now we can use this dates dictionary to sort and identify the pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f391ec81",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ⏰ record the time for this cell -- usually 2–4 mins\n",
    "\n",
    "# create a list of record pairs where each entry is a list of two indices\n",
    "pairs = []\n",
    "\n",
    "# iterate over the indices from the dupes list\n",
    "for i in df_dupes:\n",
    "    # set the date to the date from index i\n",
    "    date_i = df.loc[i].date\n",
    "    # iterate over OTHER indices who share that date\n",
    "    for j in dates_dict[date_i]:\n",
    "        # check for a match\n",
    "        if df_pairs.loc[i].equals(df_pairs.loc[j]) and df.drugName.loc[i] != df.drugName.loc[j]:\n",
    "            # remove this index from the dates dictionary so we have fewer to search through in later iterations\n",
    "            dates_dict[date_i].remove(j)\n",
    "            # add this pair to the pairs list\n",
    "            pairs.append([i,j])\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b8094a",
   "metadata": {},
   "source": [
    "Let's take a look at several of the pairs we've collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d1444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220fa660",
   "metadata": {},
   "source": [
    "Here we'll create a dictionary that matches the index of one pair member to the other member of the pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d218c662",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_dict = {}\n",
    "\n",
    "for pair in pairs:\n",
    "    for i in range(2):\n",
    "        pairs_dict[pair[i]] = pair[1-i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46faf5a",
   "metadata": {},
   "source": [
    "# restore missing condition labels\n",
    "\n",
    "We will restore missing condition labels in two ways, in order of certainty:\n",
    "\n",
    "1. For missing values that possess a pair match, we will assign it the condition of its match.\n",
    "2. For the remaining missing values, we will assign it the condition that is most commonly associated with its drug name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20fc91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c848c7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ⏰ record the time for this cell -- usually 10-15 seconds\n",
    "\n",
    "# iterate over each record pair\n",
    "for pair in pairs:\n",
    "    # iterate over each member of the pair\n",
    "    for i in range(2):\n",
    "        # identify a pair member whose condition is missing\n",
    "        if df.loc[pair[i]].condition == 'missing':\n",
    "            # assign to the pair member the condition of its pair-mate\n",
    "            df.at[pair[i], 'condition'] = df.loc[pairs_dict[pair[i]]].condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d037af",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeab6616",
   "metadata": {},
   "source": [
    "Because it will be useful later, we'll make a feature that names the indicated drug and, if applicable, the paired drug.\n",
    "\n",
    "This is not a *final* replacement for the drug name feature, but it will allow us to better recognize the relationship between the generic and brand drug names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba26b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ⏰ record the time for this cell -- usually 15-30 seconds\n",
    "\n",
    "df['ind'] = df.index\n",
    "\n",
    "def drugList_fix(index, drugName_):\n",
    "    drugList = [drugName_]\n",
    "    if index in pairs_dict:\n",
    "        drugList.append(df.loc[pairs_dict[index]].drugName)\n",
    "        # alphabetize each drug pair so that we will not mistakenly duplicate e.g. [A,B] & [B,A]\n",
    "        drugList.sort()\n",
    "    return drugList\n",
    "\n",
    "df['drugList'] = df.apply(lambda x: drugList_fix(x.ind, x.drugName), axis=1)\n",
    "\n",
    "df.drop(columns='ind', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4f48e1",
   "metadata": {},
   "source": [
    "Now we can create a feature that tells us if a record is associated with a paired drug name or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2c3e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['isPaired'] = df.drugList.apply(lambda x: True if len(x) > 1 else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89968a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.isPaired])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2541055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[~df.isPaired])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1910bcb",
   "metadata": {},
   "source": [
    "Because lists confuse certain operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f572c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['drugSetString'] = df.drugList.apply(lambda x: x[0] + ' ' + x[1] if len(x) == 2 else x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90528ffc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(df[df.duplicated(subset=df.columns.difference(['drugName', 'drugSet', 'drugList']))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1527cb1a",
   "metadata": {},
   "source": [
    "With this new feature in place, we can drop one record from each of the brand/generic pairs. The drug name feature will retain only one member of the pair -- unpredictably either the brand or the generic -- which will make this feature more or less useless for the moment.\n",
    "\n",
    "Before we drop these records, we'll create a bookmark copy of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6b2b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT re-run this cell out of sequence\n",
    "# to use the dataframe as it was at this stage,\n",
    "# in ANOTHER CELL write the code `df = df_bookmark_1.copy()` and immediately delete that code\n",
    "df_bookmark_1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0ef081",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=df.columns.difference(['drugName', 'drugSet', 'drugList']), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7cfbd2",
   "metadata": {},
   "source": [
    "For every remaining record with a missing condition, we will assign it the condition that is most common for the drug indicated by that record. (This will not be biased by duplicates from brand/generic pairs, because we have dropped those duplicates.)\n",
    "\n",
    "This will be the last use we have for conditions *not* treated by Planned Parenthood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13621e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs_w_missing_condition = list(set(df[df.condition == 'missing'].drugSetString))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad6eaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(drugs_w_missing_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eefce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drugSetString.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8459949c",
   "metadata": {},
   "source": [
    "This applies to some 20% of the drugs. We'll create a dictionary that reports the most common condition for these drugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04242a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# record the time for this cell -- 10-20 seconds\n",
    "\n",
    "most_common_condition = {}\n",
    "\n",
    "for drug in drugs_w_missing_condition:\n",
    "    condition = df[df.drugSetString == drug].condition.value_counts().idxmax()\n",
    "    if condition == 'missing' and len(set(df[df.drugSetString == drug].condition)) > 1:\n",
    "        condition = df[(df.drugSetString == drug) &\n",
    "                       (df.condition != 'missing')\n",
    "                      ].condition.value_counts().idxmax()\n",
    "    proportion = round(df[df.drugSetString == drug].condition.value_counts(normalize=True)[0],2)\n",
    "    most_common_condition[drug] = [condition, proportion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa04afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_condition['Sildenafil Viagra']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5410ef5",
   "metadata": {},
   "source": [
    "For example, if a review with an unlisted condition is about Viagra, we will assume the condition is Erectile \n",
    "Dysfunction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1861b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c9ce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['condition'] = df.apply(lambda x: most_common_condition[x.drugSetString][0] \\\n",
    "                           if x.condition == 'missing' \\\n",
    "                           else x.condition, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304be2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80305299",
   "metadata": {},
   "source": [
    "This is how many records there are that still have no condition label. This means the drugs indicated in these records are *only* indicated in references without an indicated condition. As such, there's not really anything we can do with these records, and we may as well drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2d553a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df.condition == 'missing'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00640197",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1de51f6",
   "metadata": {},
   "source": [
    "# trim by conditions\n",
    "\n",
    "At this point, we still have more cleaning to do, but we have identified all the conditions that we can, and we won't have any further need for records with certain condition values, so we'll drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15970475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT re-run this cell out of sequence\n",
    "# to use the dataframe as it was at this stage,\n",
    "# in ANOTHER CELL write the code `df = df_bookmark_2.copy()` and immediately delete that code\n",
    "df_bookmark_2 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fff3ec",
   "metadata": {},
   "source": [
    "Let's take another look at the complete list of conditions and choose which ones to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f25826",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8e325e",
   "metadata": {},
   "source": [
    "Since there are so many conditions to consider, let's limit this to just conditions with at least 25 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af709e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "display(df['condition'].value_counts().loc[lambda x: x >= 25])\n",
    "pd.set_option(\"display.max_rows\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a934bf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_conditions = [\n",
    "    'Birth Control', 'Emergency Contraception', 'Abnormal Uterine Bleeding', \\\n",
    "    'Menstrual Disorders', 'Female Infertility', 'Uterine Fibroids'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec60152",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[~df.condition.isin(pp_conditions)].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755550f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f90f58",
   "metadata": {},
   "source": [
    "# exploring generic and brand names\n",
    "\n",
    "Now that we have a smaller number of records to deal with, we can sort out generic and brand names.\n",
    "\n",
    "First we'll create a list of all values from the drug name feature. (Some of these have been dropped from the drug name feature itself when we dropped one record from each brand/generic pair, but all of them were included in the drug list feature.)\n",
    "\n",
    "We'll create two lists: paired drugs (which we will attempt to sort into brand and generic) and single drugs (each of which we will then try to identify as either brand or generic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e521858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207878be",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_drug_lists = df.drugList.tolist()\n",
    "all_drug_lists.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c3e878",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_drug_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20b5e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_drug_names = set()\n",
    "\n",
    "for list_ in all_drug_lists:\n",
    "    all_drug_names.add(list_[0])\n",
    "    if len(list_) > 1:\n",
    "        all_drug_names.add(list_[1])\n",
    "\n",
    "all_drug_names = list(all_drug_names)\n",
    "\n",
    "all_drug_names.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05e943e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_drug_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2c0455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will create a full list with duplicates\n",
    "# we need to do this intermediate before moving to the following step to remove duplicates\n",
    "paired_drug_lists = df[df.isPaired].drugList.tolist()\n",
    "paired_drug_lists.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433f287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(paired_drug_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f44a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_drug_names = set()\n",
    "\n",
    "for pair in paired_drug_lists:\n",
    "    paired_drug_names.add(pair[0])\n",
    "    paired_drug_names.add(pair[1])\n",
    "\n",
    "paired_drug_names = list(paired_drug_names)\n",
    "\n",
    "paired_drug_names.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c18892",
   "metadata": {},
   "outputs": [],
   "source": [
    "unpaired_drug_names = [drug for drug in all_drug_names if drug not in paired_drug_names]\n",
    "\n",
    "unpaired_drug_names.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1470d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(paired_drug_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4045a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unpaired_drug_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd75120",
   "metadata": {},
   "source": [
    "Together, these two lists of names constitute all the drug names left to sort into brand and generic categories.\n",
    "\n",
    "In order to sort the list of paired drugs into brand and generic, we'll establish a dictionary whose keys are all the drug names that appear in a generic/brand pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ce3d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_dict = {}\n",
    "\n",
    "for drug in paired_drug_names:\n",
    "    drug_dict[drug] = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eee2df9",
   "metadata": {},
   "source": [
    "We'll assign values to those keys according to the pairings. For example, if drug name A is in a generic/brand pair with drug name B, then they will appear on each other's list of values in this dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de3ae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in paired_drug_lists:\n",
    "    drug_dict[pair[0]].add(pair[1])\n",
    "    drug_dict[pair[1]].add(pair[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6258a92",
   "metadata": {},
   "source": [
    "Let's find out how many of these drug names are associated with exactly one other drug name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcda048",
   "metadata": {},
   "outputs": [],
   "source": [
    "len({drug for drug in drug_dict if len(drug_dict[drug]) == 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16599cf3",
   "metadata": {},
   "source": [
    "That should mean that exactly the remainder are associated with multiple drug names. It would make sense that drug names that belong to multiple generic/brand pairs are themselves the generic name. On that assumption, we'll create a list of generic drug names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071ce431",
   "metadata": {},
   "outputs": [],
   "source": [
    "generics = [drug for drug in drug_dict if len(drug_dict[drug]) > 1]\n",
    "\n",
    "generics.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cb94fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(generics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7cc978",
   "metadata": {},
   "source": [
    "Now we'll check to make sure that the drug names we've just designated as \"generic\" do NOT belong to a generic/brand pair with *another* \"generic\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8250e5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for drug in generics:\n",
    "    for match in drug_dict[drug]:\n",
    "        if match in generics:\n",
    "            count += 1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b374427e",
   "metadata": {},
   "source": [
    "Great.\n",
    "\n",
    "Then we can begin designating drug names as \"brands\" if they are in a generic/brand pair with a generic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0101019",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands = set()\n",
    "\n",
    "for generic in generics:\n",
    "    for match in drug_dict[generic]:\n",
    "        brands.add(match)\n",
    "\n",
    "brands = list(brands)\n",
    "\n",
    "brands.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1907ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(brands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12945679",
   "metadata": {},
   "source": [
    "Now let's see what drugs remain and how many records they are associated with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c64e760",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncategorized = list(set(drug for drug in paired_drug_names if drug not in generics and drug not in brands))\n",
    "\n",
    "uncategorized.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93303b2c",
   "metadata": {},
   "source": [
    "To be clear, these are drug names with the following properties:\n",
    "\n",
    "- the drug name belongs to an exclusive brand/generic pair\n",
    "- we have not yet identified which members of the pair are brand and generic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1c3c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(uncategorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2f5197",
   "metadata": {},
   "source": [
    "We should be able to list all of these drug names in their pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251824b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated = set()\n",
    "for drug in uncategorized:\n",
    "    if drug not in repeated:\n",
    "        print(drug, '||', list(drug_dict[drug])[0])\n",
    "        repeated.add(drug)\n",
    "        repeated.add(list(drug_dict[drug])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81d3365",
   "metadata": {},
   "source": [
    "With so few pairs, we can Google the names to determine which names of a pair are generic and brand names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac1a46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_brands = [\n",
    "    'Clomid', 'Premarin', 'ParaGard', 'Natazia', 'NuvaRing', 'Femara', \\\n",
    "    'Glucophage', 'Lysteda', 'Megace', 'Necon 1 / 50', 'ella'\n",
    "]\n",
    "\n",
    "brands.extend(new_brands)\n",
    "\n",
    "len(brands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f521f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for drug in new_brands:\n",
    "    generics.append(list(drug_dict[drug])[0])\n",
    "\n",
    "len(generics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb17bc0",
   "metadata": {},
   "source": [
    "At this point, we have sorted all the paired brand and generic drug names. What remains is to identify whether each of the single drug names is a generic or brand name.\n",
    "\n",
    "Let's look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab7b0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "unpaired_drug_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0296b2",
   "metadata": {},
   "source": [
    "Simple Google search confirms these are both generic names, so we'll add them as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8dee85",
   "metadata": {},
   "outputs": [],
   "source": [
    "generics.extend(unpaired_drug_names)\n",
    "\n",
    "generics.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18b4e6e",
   "metadata": {},
   "source": [
    "Now we create a more universal drug naming system whereby every record is identified with its generic name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6a7c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic_fix(drugList):\n",
    "    if len(drugList) == 1 or drugList[0] in generics:\n",
    "        return drugList[0]\n",
    "    else:\n",
    "        return drugList[1]\n",
    "\n",
    "df['genericName'] = df.drugList.apply(lambda x: generic_fix(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4f82f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_brand_fix(drugList):\n",
    "    if len(drugList) == 1:\n",
    "        return None\n",
    "    elif drugList[0] in brands:\n",
    "        return drugList[0]\n",
    "    else:\n",
    "        return drugList[1]\n",
    "\n",
    "df['fullBrandName'] = df.drugList.apply(lambda x: full_brand_fix(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e8d1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_dict = {}\n",
    "\n",
    "for fullName in brands:\n",
    "    name = fullName\n",
    "    tail = name.split()[-1]\n",
    "    while tail.isnumeric() or tail in ['Fe', 'Lo', 'One-Step', '/', '1.5', 'Contraceptive']:\n",
    "        name = name[:len(name)-len(tail)-1]\n",
    "        tail = name.split()[-1]\n",
    "    head = name.split()[0]\n",
    "    while head in ['Lo', '/']:\n",
    "        name = name[len(head)+1:]\n",
    "        head = name.split()[0]\n",
    "    brand_dict[fullName] = name\n",
    "\n",
    "df['shortBrandName'] = df.fullBrandName.apply(lambda x: None if x == None else brand_dict[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792b34b8",
   "metadata": {},
   "source": [
    "# further exploration of duplicates\n",
    "\n",
    "Now we'll turn to more possible duplicate instances. We suspect the same user has copy-pasted an identical review multiple times when that verbatim review appears for the same condition and (generic) drug name with the same rating. Let's look at all such instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e61183",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.duplicated(subset=['genericName', 'condition', 'review', 'rating'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c680639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated(subset=['genericName', 'condition', 'review', 'rating'])] \\\n",
    "[['genericName', 'condition', 'review', 'rating', 'date']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f747523",
   "metadata": {},
   "source": [
    "The review texts all appear to be unique. As long as the review and its duplicate appear close in time to one another (within days), then these should be collapsed into a single review with the respective useful counts added together.\n",
    "\n",
    "First we'll check on the dates. The following cell will show the respective dates of when these duplicated reviews appeared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564d4c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in df[df.duplicated(subset=['genericName', 'condition', 'review', 'rating'])].index:\n",
    "    two_indices = list(df[df.review == df.loc[ind].review].index)\n",
    "    print(df.loc[two_indices[0]].date, '... and ...', df.loc[two_indices[1]].date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70abd086",
   "metadata": {},
   "source": [
    "They're all identical dates except one that is a day apart.\n",
    "\n",
    "We'll collapse these into single records and add the useful counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6901d82b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ind in df[df.duplicated(subset=['genericName', 'condition', 'review', 'rating'])].index:\n",
    "    two_indices = list(df[df.review == df.loc[ind].review].index)\n",
    "    x, y = two_indices[0], two_indices[1]\n",
    "    count = int(df.loc[x].usefulCount + df.loc[y].usefulCount)\n",
    "    df.at[x, 'usefulCount'] = count\n",
    "    df.drop([y], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d91e45",
   "metadata": {},
   "source": [
    "# exploring final data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcb3ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rating.hist(bins=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f57d85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10ae8a8",
   "metadata": {},
   "source": [
    "# save and reload preprocessed set\n",
    "\n",
    "At this stage we will save and reload the preprocessed set in order to avoid taking the time to repeat earlier work everytime we open the notebook.\n",
    "\n",
    "The saved version has restored or deleted all records with missing condition labels.\n",
    "\n",
    "We have established pairs in the list `twins` but we have NOT yet deleted either member of any pair or dealt with the confusion between brand and generic drug names.\n",
    "\n",
    "The size of the dateframe is nearly the same as its original version, roughly 215,000 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39e1fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = Path('../data/preprocessed.csv')\n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b1376e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store twins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7741561",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/preprocessed.csv')\n",
    "df.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33676e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r twins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e4665d",
   "metadata": {},
   "source": [
    "# feature engineering ideas\n",
    "\n",
    "- word count\n",
    "- character count\n",
    "- words in all caps\n",
    "- average word length\n",
    "- whether words are in English (spelled correctly)\n",
    "- whether it includes characters such as exclamation points, question marks, (especially repeatedly), and emoticons\n",
    "- whether it mentions the brand or generic name in the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18956e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'] = df.review.apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e48becc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['char_count'] = df.review.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc9c32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'!' in df.loc[5].review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29db80b",
   "metadata": {},
   "source": [
    "# rudimentary word cloud maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67448b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bookmark_3 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e12dc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_lower'] = df['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64df7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.condition == 'Birth Control']\n",
    "\n",
    "def sentiment_fix(rating):\n",
    "    if rating > 8:\n",
    "        return 1\n",
    "    elif rating < 2:\n",
    "        return 0\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df['sentiment'] = df.rating.apply(lambda x: sentiment_fix(x))\n",
    "\n",
    "df_pos = df[df.sentiment == 1]\n",
    "\n",
    "df_neg = df[df.sentiment == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f216cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list of all reviews\n",
    "reviews_pos = df_pos.review_lower.to_list()\n",
    "reviews_neg = df_neg.review_lower.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac87d0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make tokenizer\n",
    "# tokenizer = TweetTokenizer(\n",
    "#     preserve_case=False,\n",
    "#     strip_handles=True\n",
    "# )\n",
    "\n",
    "# create list of tokens from data set\n",
    "tokens_pos = word_tokenize(','.join(reviews_pos))\n",
    "tokens_neg = word_tokenize(','.join(reviews_neg))\n",
    "\n",
    "\n",
    "# tokens = [word for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8deeb6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# lemmatize the list of words\n",
    "tokens_lemmatized_pos = [lemmatizer.lemmatize(word) for word in tokens_pos]\n",
    "tokens_lemmatized_neg = [lemmatizer.lemmatize(word) for word in tokens_neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49071a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the most frequently occurring tokens\n",
    "FreqDist(tokens_lemmatized_pos).most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e545482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the most frequently occurring tokens\n",
    "FreqDist(tokens_lemmatized_neg).most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497bd268",
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives = ['no', 'not', \"don't\", \"aren't\", \"couldn't\", \"didn't\", \"doesn't\", \"hadn't\", \"hasn't\", \"haven't\", \\\n",
    "             \"isn't\", \"wasn't\", \"weren't\", \"won't\", \"wouldn't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f27776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the standard list of stopwords\n",
    "nltk.download('stopwords', quiet=True)\n",
    "# start our own list of stopwords with these words\n",
    "stop_list = [word for word in stopwords.words('english') if word not in negatives]\n",
    "# add punctuation characters\n",
    "for char in string.punctuation:\n",
    "    stop_list.append(char)\n",
    "# add empty string\n",
    "stop_list.extend(['', 'ha', 'wa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a15ac51",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1906820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make stopped list of tokens\n",
    "tokens_stopped_pos = [word for word in tokens_lemmatized_pos if word not in stop_list]\n",
    "tokens_stopped_neg = [word for word in tokens_lemmatized_neg if word not in stop_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa5bc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the most frequently occurring tokens\n",
    "FreqDist(tokens_stopped_pos).most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90a03e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the most frequently occurring tokens\n",
    "FreqDist(tokens_stopped_neg).most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9578f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that generates a word cloud of a given list of words\n",
    "def make_wordcloud(wordlist, colormap='Greens', title=None):\n",
    "    # instantiate wordcloud\n",
    "    wordcloud = WordCloud(\n",
    "        width=600,\n",
    "        height=400,\n",
    "        colormap=colormap,\n",
    "        collocations = True\n",
    "    )\n",
    "    return wordcloud.generate(','.join(wordlist))\n",
    "\n",
    "def plot_wordcloud(wordcloud):\n",
    "    # plot wordcloud\n",
    "    plt.figure(figsize = (12, 15)) \n",
    "    plt.imshow(wordcloud) \n",
    "    plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e9471a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word cloud of stopped words\n",
    "plot_wordcloud(make_wordcloud(tokens_stopped_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc8a326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word cloud of stopped words\n",
    "plot_wordcloud(make_wordcloud(tokens_stopped_neg, colormap='Reds'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bda9bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['logUsefulCount'] = df.usefulCount.apply(lambda x: np.log(x) if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d467a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('rating').usefulCount.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43563f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ccf2a2",
   "metadata": {},
   "source": [
    "# end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
