{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "998e0418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "043b8658",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.read_csv('../data/drugsComTrain_raw.tsv', delimiter='\\t', encoding='latin-1')\n",
    "d2 = pd.read_csv('../data/drugsComTest_raw.tsv', delimiter='\\t', encoding='latin-1')\n",
    "df = pd.concat([d1,d2]).reset_index().drop(columns=['Unnamed: 0', 'index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71f7269f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Valsartan</td>\n",
       "      <td>Left Ventricular Dysfunction</td>\n",
       "      <td>\"It has no side effect, I take it in combinati...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>May 20, 2012</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Guanfacine</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>\"My son is halfway through his fourth week of ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>April 27, 2010</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lybrel</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>December 14, 2009</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ortho Evra</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"This is my first time using any form of birth...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>November 3, 2015</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Buprenorphine / naloxone</td>\n",
       "      <td>Opiate Dependence</td>\n",
       "      <td>\"Suboxone has completely turned my life around...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>November 27, 2016</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Pyridium</td>\n",
       "      <td>Dysuria</td>\n",
       "      <td>\"I&amp;#039;ve been having UTIs for 7 years, my mo...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>October 13, 2016</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Latuda</td>\n",
       "      <td>Bipolar Disorde</td>\n",
       "      <td>\"I have had great experience so far with Latud...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>February 20, 2012</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Bupropion</td>\n",
       "      <td>Smoking Cessation</td>\n",
       "      <td>\"Love this, no mouth sores, or ulcers like Wel...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>August 22, 2014</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Implanon</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"Never again! After being on depo I was suppos...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>August 20, 2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Effexor XR</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>\"Was on this med for 5 years. Worked fine but ...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>December 27, 2016</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    drugName                     condition  \\\n",
       "0                  Valsartan  Left Ventricular Dysfunction   \n",
       "1                 Guanfacine                          ADHD   \n",
       "2                     Lybrel                 Birth Control   \n",
       "3                 Ortho Evra                 Birth Control   \n",
       "4   Buprenorphine / naloxone             Opiate Dependence   \n",
       "..                       ...                           ...   \n",
       "56                  Pyridium                       Dysuria   \n",
       "57                    Latuda               Bipolar Disorde   \n",
       "58                 Bupropion             Smoking Cessation   \n",
       "59                  Implanon                 Birth Control   \n",
       "60                Effexor XR                       Anxiety   \n",
       "\n",
       "                                               review  rating  \\\n",
       "0   \"It has no side effect, I take it in combinati...     9.0   \n",
       "1   \"My son is halfway through his fourth week of ...     8.0   \n",
       "2   \"I used to take another oral contraceptive, wh...     5.0   \n",
       "3   \"This is my first time using any form of birth...     8.0   \n",
       "4   \"Suboxone has completely turned my life around...     9.0   \n",
       "..                                                ...     ...   \n",
       "56  \"I&#039;ve been having UTIs for 7 years, my mo...     1.0   \n",
       "57  \"I have had great experience so far with Latud...     8.0   \n",
       "58  \"Love this, no mouth sores, or ulcers like Wel...    10.0   \n",
       "59  \"Never again! After being on depo I was suppos...     2.0   \n",
       "60  \"Was on this med for 5 years. Worked fine but ...     6.0   \n",
       "\n",
       "                 date  usefulCount  \n",
       "0        May 20, 2012           27  \n",
       "1      April 27, 2010          192  \n",
       "2   December 14, 2009           17  \n",
       "3    November 3, 2015           10  \n",
       "4   November 27, 2016           37  \n",
       "..                ...          ...  \n",
       "56   October 13, 2016            8  \n",
       "57  February 20, 2012           39  \n",
       "58    August 22, 2014           15  \n",
       "59    August 20, 2015            1  \n",
       "60  December 27, 2016           23  \n",
       "\n",
       "[61 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:61]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf152c95",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90b31b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_review(index):\n",
    "    print(df.review.loc[index])\n",
    "    display(df[df.review == df.loc[index].review][['drugName', 'condition', 'rating', 'date', 'usefulCount']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ab9d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_similar(index):\n",
    "    \n",
    "    count_total = df[\n",
    "        (df.drugName == df.loc[index].drugName) & \\\n",
    "        (df.condition == df.loc[index].condition) & \\\n",
    "        (df.date == df.loc[index].date)\n",
    "    ].review.count()\n",
    "    \n",
    "    count_similar = df[\n",
    "        (df.drugName == df.loc[index].drugName) & \\\n",
    "        (df.condition == df.loc[index].condition) & \\\n",
    "        (df.rating == df.loc[index].rating) & \\\n",
    "        (df.date == df.loc[index].date)\n",
    "    ].review.count()\n",
    "    \n",
    "    print('On', df.loc[index].date, df.loc[index].drugName, 'was reviewed', count_total, \\\n",
    "          'times and received a rating of', df.loc[index].rating, count_similar, 'times.\\n')\n",
    "    print('From that date, here are all', count_similar, 'reviews with the same rating:\\n')\n",
    "    for ind in df[\n",
    "        (df.drugName == df.loc[index].drugName) & \\\n",
    "        (df.condition == df.loc[index].condition) & \\\n",
    "        (df.rating == df.loc[index].rating) & \\\n",
    "        (df.date == df.loc[index].date)\n",
    "    ].index:\n",
    "        print(df.loc[ind].review,'\\n')\n",
    "    \n",
    "    print('Here is a breakdown of all the dates when reviewers gave the same drug name and condition THIS RATING:')\n",
    "    display(df[\n",
    "        (df.drugName == df.loc[index].drugName) & \\\n",
    "        (df.condition == df.loc[index].condition) & \\\n",
    "        (df.rating == df.loc[index].rating)\n",
    "    ].date.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dc5757",
   "metadata": {},
   "source": [
    "# missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa8e139",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition.isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f04cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition.fillna('missing', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69d5821",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50d8ae2",
   "metadata": {},
   "source": [
    "We noticed another condition label that was meant to indicate missing and should be accordingly changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f219b38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition = df.condition.apply(lambda x: 'missing' if 'Not Listed' in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4defc466",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce25ecf",
   "metadata": {},
   "source": [
    "We've identified some actual missing condition labels, but we noticed there are more condition labels that seem suspicious, particularly ones that start with something other than an upper case character. Let's look at all such condition labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f047dcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df[(~df.condition.str[0].isin(list(string.ascii_uppercase))) &\n",
    "   (df.condition != 'missing')\n",
    "  ].condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6695f3",
   "metadata": {},
   "source": [
    "These fall into three categories. Ones that include \"users found this comment helpful\" should be regarded as erroneous and therefore missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d357be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition = df.condition.apply(lambda x: 'missing' if 'users found' in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b230783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8057a09",
   "metadata": {},
   "source": [
    " Ones that show a clipped copy of the drug name and end with a parenthesis should also be regarded as missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6021301",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition = df.condition.apply(lambda x: 'missing' \\\n",
    "                                  if x[0] not in list(string.ascii_uppercase) and \\\n",
    "                                  x[-1] in ['(', ')'] \\\n",
    "                                  else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2469df56",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a56c978",
   "metadata": {},
   "source": [
    "Most of the ones that show a clipped version of the condition label can possibly be restored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfba7826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition_restore(condition):\n",
    "    if condition.split()[-1] in ['Disorde', 'eve', 'Shoulde', 'Cance']:\n",
    "        condition = condition+'r'\n",
    "    if condition.split()[0] in ['acial', 'ibrocystic', 'ungal', 'amilial', 'ailure', 'ever', \\\n",
    "                                'emale', 'unctional', 'actor', 'ibromyalgia', 'atigue']:\n",
    "        condition = 'F'+condition\n",
    "    if condition.split()[0] in ['llicular', 'llicle', 'lic', 'cal']:\n",
    "        condition = 'Fo'+condition\n",
    "    if condition.split()[0] in ['mance']:\n",
    "        condition = 'Perfor'+condition\n",
    "    if condition.split()[0] in ['zen']:\n",
    "        condition = 'Fro'+condition\n",
    "    if condition.split()[0] in ['mis']:\n",
    "        condition = 'Dermatitis Herpetifor'+condition\n",
    "    return condition\n",
    "\n",
    "df.condition = df.condition.apply(lambda x: condition_restore(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90e6d91",
   "metadata": {},
   "source": [
    "Let's look at what we have left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eead35",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df[(~df.condition.str[0].isin(list(string.ascii_uppercase))) &\n",
    "   (df.condition != 'missing')\n",
    "  ].condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f225d4f",
   "metadata": {},
   "source": [
    "\"von Willebrand's Disease\" appears to be a naturally uncapitalized condition. The others have been impossible to restore and will also be regarded as missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37b05b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition = df.condition.apply(lambda x: 'missing' \\\n",
    "                                  if x[0] not in list(string.ascii_uppercase) and \\\n",
    "                                  x.split()[0] != 'von' \\\n",
    "                                  else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c8e9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7d79d9",
   "metadata": {},
   "source": [
    "## proposed solutions for missing values\n",
    "\n",
    "1. For every record with a missing condition, we will assign it the condition that is most common for the drug indicated by that record.\n",
    "\n",
    "2. Before executing solution 1, find each record's twin and use the condition label from the twin where applicable.\n",
    "\n",
    "For now, we'll just execute solution 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e174a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs_w_missing_condition = list(set(df[df.condition == 'missing'].drugName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb07bcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(drugs_w_missing_condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1153e206",
   "metadata": {},
   "source": [
    "This applies to about a quarter of the drugs. We'll create a dictionary that reports the most common condition for these drugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d916b752",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_condition = {}\n",
    "\n",
    "for drug in drugs_w_missing_condition:\n",
    "    condition = df[df.drugName == drug].condition.value_counts().idxmax()\n",
    "    if condition == 'missing' and len(set(df[df.drugName == drug].condition)) > 1:\n",
    "        condition = df[(df.drugName == drug) &\n",
    "                       (df.condition != 'missing')\n",
    "                      ].condition.value_counts().idxmax()\n",
    "    proportion = round(df[df.drugName == drug].condition.value_counts(normalize=True)[0],2)\n",
    "    most_common_condition[drug] = [condition, proportion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31a5698",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_condition['Viagra']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b8eb2a",
   "metadata": {},
   "source": [
    "For example, if a review with an unlisted condition is about Viagra, we will assume the condition is Erectile Dysfunction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a795e31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['condition'] = df.apply(lambda x: most_common_condition[x.drugName][0] \\\n",
    "                           if x.condition == 'missing' \\\n",
    "                           else x.condition, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed9bcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.condition == 'missing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87814f6b",
   "metadata": {},
   "source": [
    "This is how many records there are that still have no label for condition. This means the drugs indicated in these records are *only* indicated in references without an indicated condition. They may still have a \"twin\" records that we could match them to, but while we're skipping that solution step, there's not really anything we can do with these records, and we may as well drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbffcb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df.condition == 'missing'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b660e887",
   "metadata": {},
   "source": [
    "# duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598e06fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc32f5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79b8091",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_review(178703)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1741c6e9",
   "metadata": {},
   "source": [
    "This is curious. The same review is recorded four times. There are two identical pairs, where the difference between the pairs is the drug name. We can drop one from each pair, but this will need to be revisited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c94bf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f3505d",
   "metadata": {},
   "source": [
    "# contractions\n",
    "\n",
    "Here is an example of a contraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e977f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.review[3][56:69]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20666ce9",
   "metadata": {},
   "source": [
    "Here is how the html function fixes it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800bd811",
   "metadata": {},
   "outputs": [],
   "source": [
    "html.unescape(df.loc[3][2])[56:64]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28c4bfa",
   "metadata": {},
   "source": [
    "Here is how the contractions function fixes (the html function's fix of) it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299a096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions.fix(html.unescape(df.loc[3][2]))[56:65]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277e7c87",
   "metadata": {},
   "source": [
    "Here is an instance of \"ain't\" with the same functions applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a00f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.review.loc[507][75:99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ddba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "html.unescape(df.review.loc[507])[75:94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858f11a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions.fix(html.unescape(df.review.loc[507]))[75:96]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34618dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.review.str.contains('ain&#039;t')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71412442",
   "metadata": {},
   "source": [
    "There are 53 instances of \"ain't\".\n",
    "\n",
    "I'm currently having difficulty downloading the package that appropriately fixes \"ain't\" into \"is not\" or \"are not\" etc. This shouldn't matter after I remove stop words. I think it will be helpful to exclude negatives like \"no\" and \"not\" from the stop words. It could certainly be of help to look for bigrams like \"not good\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b831a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.review = df.review.apply(lambda x: html.unescape(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de01bb43",
   "metadata": {},
   "source": [
    "# make some dummy dfs to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d421a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old = df.copy()\n",
    "len(df_old[df_old.duplicated(subset = df_old.columns.difference(['drugName']))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2681273",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bc = df_old.drop(df_old[df_old.condition != 'Birth Control'].index)\n",
    "len(df_bc[df_bc.duplicated(subset = df_bc.columns.difference(['drugName']))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39863a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_20000 = df_bc[df_bc.index.isin(np.random.choice(df_bc.index.tolist(), 20000, replace=False))]\n",
    "len(df_20000[df_20000.duplicated(subset = df_20000.columns.difference(['drugName']))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4f0c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10000 = df_bc[df_bc.index.isin(np.random.choice(df_bc.index.tolist(), 10000, replace=False))]\n",
    "len(df_10000[df_10000.duplicated(subset = df_10000.columns.difference(['drugName']))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b30f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5000 = df_bc[df_bc.index.isin(np.random.choice(df_bc.index.tolist(), 5000, replace=False))]\n",
    "len(df_5000[df_5000.duplicated(subset = df_5000.columns.difference(['drugName']))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34370197",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2000 = df_bc[df_bc.index.isin(np.random.choice(df_bc.index.tolist(), 2000, replace=False))]\n",
    "len(df_2000[df_2000.duplicated(subset = df_2000.columns.difference(['drugName']))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b24176b",
   "metadata": {},
   "source": [
    "# date buckets with df_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d35ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_bc.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461f9ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='drugName', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4224c281",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dates_bucket = {}\n",
    "for date in list(set(df[~df.index.isin(bucket_A)].date.tolist())):\n",
    "    dates_bucket[date] = []\n",
    "for i in df.index:\n",
    "    dates_bucket[df.loc[i].date].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d7299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "found_pairs = 0\n",
    "twins = []\n",
    "\n",
    "for i in bucket_A:\n",
    "    date_i = df.loc[i].date\n",
    "    for j in dates_bucket[date_i]:\n",
    "        if df.loc[i].equals(df.loc[j]):\n",
    "            found_pairs += 1\n",
    "            dates_bucket[date_i].remove(j)\n",
    "            twins.append([i,j])\n",
    "            break\n",
    "print(found_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672be3bb",
   "metadata": {},
   "source": [
    "# date buckets with 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f40b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_20000.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c59b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='drugName', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b185d688",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bucket_A = df[df.duplicated].index.tolist()\n",
    "dates_bucket = {}\n",
    "for date in list(set(df[~df.index.isin(bucket_A)].date.tolist())):\n",
    "    dates_bucket[date] = []\n",
    "for i in df.index:\n",
    "    dates_bucket[df.loc[i].date].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf09d422",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "found_pairs = 0\n",
    "twins = []\n",
    "\n",
    "for i in bucket_A:\n",
    "    date_i = df.loc[i].date\n",
    "    for j in dates_bucket[date_i]:\n",
    "        if df.loc[i].equals(df.loc[j]):\n",
    "            found_pairs += 1\n",
    "            dates_bucket[date_i].remove(j)\n",
    "            twins.append([i,j])\n",
    "            break\n",
    "print(found_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa2307a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(twins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde3213c",
   "metadata": {},
   "source": [
    "# NEXT:\n",
    "\n",
    "experiment with the code below to see if separating into date buckets makes it faster.\n",
    "\n",
    "# DON'T FORGET:\n",
    "\n",
    "run tests to see whether there are triples??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56de4ecc",
   "metadata": {},
   "source": [
    "# experiment: 2,000 records // 50 duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d03d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_2000.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71e102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='drugName', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27e78f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bucket_A = df[df.duplicated].index.tolist()\n",
    "bucket_B = df[~df.index.isin(bucket_A)].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9efb6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "found_pairs = 0\n",
    "for i in bucket_A:\n",
    "    for j in bucket_B:\n",
    "        if df.loc[i].equals(df.loc[j]):\n",
    "            found_pairs += 1\n",
    "print(found_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32972d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "found_pairs = 0\n",
    "for i in bucket_A:\n",
    "    for j in bucket_B:\n",
    "        if df.loc[i].equals(df.loc[j]):\n",
    "            found_pairs += 1\n",
    "            bucket_B.remove(j)\n",
    "            break\n",
    "print(found_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abc6946",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "found_pairs = 0\n",
    "twins = []\n",
    "bucket_B = df[~df.index.isin(bucket_A)].index.tolist()\n",
    "for i in bucket_A:\n",
    "    for j in bucket_B:\n",
    "        if df.loc[i].equals(df.loc[j]):\n",
    "            found_pairs += 1\n",
    "            bucket_B.remove(j)\n",
    "            twins.append([i,j])\n",
    "            break\n",
    "print(found_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23e1692",
   "metadata": {},
   "source": [
    "# experiment: 5,000 records // 310 duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3510e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_5000.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f83d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='drugName', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeba4f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bucket_A = df[df.duplicated].index.tolist()\n",
    "bucket_B = df[~df.index.isin(bucket_A)].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e82d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "found_pairs = 0\n",
    "for i in bucket_A:\n",
    "    for j in bucket_B:\n",
    "        if df.loc[i].equals(df.loc[j]):\n",
    "            found_pairs += 1\n",
    "print(found_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335d5841",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "found_pairs = 0\n",
    "for i in bucket_A:\n",
    "    for j in bucket_B:\n",
    "        if df.loc[i].equals(df.loc[j]):\n",
    "            found_pairs += 1\n",
    "            bucket_B.remove(j)\n",
    "            break\n",
    "print(found_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b98e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "found_pairs = 0\n",
    "twins = []\n",
    "bucket_B = df[~df.index.isin(bucket_A)].index.tolist()\n",
    "for i in bucket_A:\n",
    "    for j in bucket_B:\n",
    "        if df.loc[i].equals(df.loc[j]):\n",
    "            found_pairs += 1\n",
    "            bucket_B.remove(j)\n",
    "            twins.append([i,j])\n",
    "            break\n",
    "print(found_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8321e4bb",
   "metadata": {},
   "source": [
    "# experiment: 5,000 records // 310 duplicates // extra dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab927804",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_5000.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826502ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='drugName', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1c8216",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bucket_A = df[df.duplicated].index.tolist()\n",
    "bucket_B = df[~df.index.isin(bucket_A)].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec73c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "found_pairs = 0\n",
    "for i in bucket_A:\n",
    "    for j in bucket_B:\n",
    "        if df.loc[i].equals(df.loc[j]):\n",
    "            found_pairs += 1\n",
    "print(found_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1378a869",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "found_pairs = 0\n",
    "for i in bucket_A:\n",
    "    for j in bucket_B:\n",
    "        if df.loc[i].equals(df.loc[j]):\n",
    "            found_pairs += 1\n",
    "            bucket_B.remove(j)\n",
    "            break\n",
    "print(found_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca700527",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "found_pairs = 0\n",
    "twins = []\n",
    "bucket_B = df[~df.index.isin(bucket_A)].index.tolist()\n",
    "for i in bucket_A:\n",
    "    for j in bucket_B:\n",
    "        if df.loc[i].equals(df.loc[j]):\n",
    "            found_pairs += 1\n",
    "            bucket_B.remove(j)\n",
    "            twins.append([i,j])\n",
    "            break\n",
    "print(found_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ff2535",
   "metadata": {},
   "source": [
    "# experiment: 39,499 records // 19,420 duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b77a99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_bc.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cd4f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='drugName', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f150414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bucket_A = df[df.duplicated].index.tolist()\n",
    "bucket_B = df[~df.index.isin(bucket_A)].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f012871a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "found_pairs = 0\n",
    "twins = []\n",
    "for i in bucket_A:\n",
    "    for j in bucket_B:\n",
    "        if df.loc[i].equals(df.loc[j]):\n",
    "            found_pairs += 1\n",
    "            bucket_B.remove(j)\n",
    "            twins.append([i,j])\n",
    "            break\n",
    "print(found_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2d18f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(twins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a7a9c4",
   "metadata": {},
   "source": [
    "# end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
